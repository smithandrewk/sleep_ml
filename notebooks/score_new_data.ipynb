{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/andrew/sleep_ml/notebooks/score_new_data.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/andrew/sleep_ml/notebooks/score_new_data.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_raw_by_path\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrew/sleep_ml/notebooks/score_new_data.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrew/sleep_ml/notebooks/score_new_data.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m batch_norm,relu\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib'"
     ]
    }
   ],
   "source": [
    "from lib.utils import load_raw_by_path\n",
    "from torch import nn\n",
    "from torch.nn.functional import batch_norm,relu\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lib.models import ResNet as MODEL\n",
    "device = 'cuda'\n",
    "EEG_1 = [1,8,14,15,16]\n",
    "EEG_2 = [3,4,5,6,7,9,10,11,12,13,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')\n",
    "i = 1\n",
    "raw = load_raw_by_path(f'data/aging/22-AGING-{i}.edf').get_data(picks=['EEG','EMG'])\n",
    "if(i in EEG_1):\n",
    "    eeg = raw[0]\n",
    "elif(i in EEG_2):\n",
    "    eeg = raw[1]\n",
    "else:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(eeg.reshape(-1,5000))\n",
    "del eeg\n",
    "# center, stretch\n",
    "X = (X - X.mean(axis=1,keepdim=True))/X.std(axis=1,keepdim=True)\n",
    "# drop row if any element is inf\n",
    "not_inf_idx = torch.where(~X.isinf().any(axis=1))[0]\n",
    "X = X[not_inf_idx].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "dataloader = DataLoader(TensorDataset(X),batch_size=64)\n",
    "y_pred = torch.Tensor().cuda()\n",
    "model.eval()\n",
    "for (X_test) in dataloader:\n",
    "    X_test = X_test[0].to(device)\n",
    "    logits = model(X_test)\n",
    "    y_pred = torch.cat([y_pred,torch.softmax(logits,dim=1).argmax(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experting\n"
     ]
    }
   ],
   "source": [
    "pred_expert = np.array(y_pred.detach().cpu()).copy()\n",
    "del y_pred\n",
    "print(\"Experting\")\n",
    "for j in range(len(pred_expert)-2):\n",
    "    if((pred_expert[j:j+2]==np.array([2,0])).all()):\n",
    "        pred_expert[j+1] = 2\n",
    "for j in range(len(pred_expert)-2):\n",
    "    if(pred_expert[j+1] != pred_expert[j] and pred_expert[j+1] != pred_expert[j+2]):\n",
    "        pred_expert[j+1] = pred_expert[j]\n",
    "df = pd.DataFrame(pred_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dists = []\n",
    "for i in tqdm(range(1,2)):\n",
    "    if i==2:\n",
    "        continue\n",
    "    raw = load_raw_by_path(f'data/aging/22-AGING-{i}.edf').get_data(picks=['EEG','EMG'])\n",
    "    if(i in EEG_1):\n",
    "        eeg = raw[0]\n",
    "    elif(i in EEG_2):\n",
    "        eeg = raw[1]\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    del raw\n",
    "\n",
    "    y_pred = softmax(model(X.cuda()),dim=1).argmax(axis=1)\n",
    "    del X\n",
    "    pred_expert = np.array(y_pred.detach().cpu()).copy()\n",
    "    del y_pred\n",
    "    print(\"Experting\")\n",
    "    for j in range(len(pred_expert)-2):\n",
    "        if((pred_expert[j:j+2]==np.array([2,0])).all()):\n",
    "            pred_expert[j+1] = 2\n",
    "    for j in range(len(pred_expert)-2):\n",
    "        if(pred_expert[j+1] != pred_expert[j] and pred_expert[j+1] != pred_expert[j+2]):\n",
    "            pred_expert[j+1] = pred_expert[j]\n",
    "    df = pd.DataFrame(pred_expert)\n",
    "    df[df[0] == 0] = 'P'\n",
    "    df[df[0] == 1] = 'S'\n",
    "    df[df[0] == 2] = 'W'\n",
    "    print(df[0].value_counts(normalize=True))\n",
    "    dists.append(df[0].value_counts(normalize=True))\n",
    "    df.to_csv(f'data/aging/{i}_pred.csv',index=False)\n",
    "\n",
    "    offset = 10e7       #epoch time period\n",
    "    rename_dict = {'W':'Sleep-Wake', 'S':'Sleep-SWS', 'P':'Sleep-Paradoxical', 'X':''}\n",
    "\n",
    "    csv_filename = f'data/aging/{i}_pred.csv'\n",
    "    zdb_filename = f'data/aging/22-AGING-{i}.zdb'\n",
    "\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    try:\n",
    "        conn = sqlite3.connect(zdb_filename)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #drop this table - creates issues\n",
    "    query = \"DROP TABLE IF EXISTS temporary_scoring_marker;\"\n",
    "    cur.execute(query)\n",
    "\n",
    "    #get keyid of scoring\n",
    "    query = \"SELECT MAX(id) FROM scoring_revision WHERE name='Machine Data'\"\n",
    "    cur.execute(query)\n",
    "    keyid = cur.fetchall()[0][0]\n",
    "\n",
    "    #get starting point for scoring\n",
    "    query = \"SELECT id FROM scoring_marker WHERE type LIKE 'Sleep%' AND key_id='\"+str(keyid)+\"';\"\n",
    "    cur.execute(query)\n",
    "    startid = cur.fetchall()[0][0]\n",
    "\n",
    "    #get start time to crreate epochs\n",
    "    query = 'SELECT starts_at FROM scoring_marker WHERE id = '+str(startid)+\";\"\n",
    "    cur.execute(query)\n",
    "    start_time = cur.fetchall()[0][0]\n",
    "    stop_time = 0\n",
    "\n",
    "    #delete first score before adding machine data\n",
    "    query = \"DELETE FROM scoring_marker;\"\n",
    "    cur.execute(query)\n",
    "\n",
    "    #insert new epochs with scoring into the table\n",
    "    for i in range(len(df)):\n",
    "        #calculate epoch\n",
    "        if i != 0:\n",
    "            start_time = stop_time\n",
    "        stop_time = start_time+offset\n",
    "\n",
    "        score = rename_dict[df.at[i,'0']]\n",
    "        #insert epoch\n",
    "        query = f\"\"\"\n",
    "                INSERT INTO scoring_marker \n",
    "                (starts_at, ends_at, notes, type, location, is_deleted, key_id)\n",
    "                VALUES \n",
    "                ({start_time}, {stop_time}, '', '{score}', '', 0, {keyid});\n",
    "                \"\"\" \n",
    "        cur.execute(query)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame()\n",
    "for dist in dists:\n",
    "    tmp = pd.concat([tmp,dist],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(tmp.T['P'].reset_index(drop=True),fill=True)\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.title(\"Paradoxical Proportion Distribution Over Aging Cohort\")\n",
    "plt.savefig(\"p.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(tmp.T['S'].reset_index(drop=True),color='green',fill=True)\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.title(\"Slow Wave Proportion Distribution Over Aging Cohort\")\n",
    "plt.savefig(\"s.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(tmp.T['W'].reset_index(drop=True),color='red',fill=True)\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.title(\"Wakefulness Proportion Distribution Over Aging Cohort\")\n",
    "plt.savefig(\"w.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
