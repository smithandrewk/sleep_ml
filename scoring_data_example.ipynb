{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPARC-10-F']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PATH_TO_DIRECTORY_OF_DATA_TO_SCORE = f'/home/andrew/sleep/data_to_score'\n",
    "MAPPING_OF_FILE_IDS_TO_CHANNEL_NAME = {\n",
    "    \"SPARC-10-M\":\"EEG 1\", \n",
    "    \"SPARC-11-M\":\"EEG 1\",\n",
    "    \"SPARC-12-M\":\"EEG 1\",\n",
    "    \"SPARC-13-M\":\"EEG 1\",\n",
    "    \"SPARC-14-M\":\"EEG 1\",\n",
    "    \"SPARC-15-M\":\"EEG 1\",\n",
    "    \"SPARC-17-M\":\"EEG 2\",\n",
    "    \"SPARC-18-M\":\"EEG 1\",\n",
    "    \"SPARC-2-F\":\"EEG 1\",\n",
    "    \"SPARC-4-F\":\"EEG 1\",\n",
    "    \"SPARC-5-F\":\"Channel-2\",\n",
    "    \"SPARC-8-F\":\"Channel-10\",\n",
    "    \"SPARC-9-F\":\"Channel-2\",\n",
    "    \"SPARC-10-F\":\"Channel-50\",\n",
    "    \"SPARC-11-F\":\"Channel-18\",\n",
    "    \"SPARC-12-F\":\"Channel-42\",\n",
    "    \"SPARC-13-F\":\"EEG 1\",\n",
    "    \"SPARC-14-F\":\"EEG 1\",\n",
    "    \"SPARC-15-F\":\"EEG 1\",\n",
    "    \"SPARC-16-F\":\"EEG 2\"\n",
    "}\n",
    "IDS = sorted(list(set([id.split('.')[0] for id in os.listdir(PATH_TO_DIRECTORY_OF_DATA_TO_SCORE)])))\n",
    "print(IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/andrew/sleep/data_to_score/SPARC-10-F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "from mne.io import read_raw_edf\n",
    "import torch\n",
    "# def score_data(id):\n",
    "id = IDS[0]\n",
    "zdb_path = f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.zdb'\n",
    "edf_path = f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.edf'\n",
    "if not os.path.exists(zdb_path):\n",
    "    raise FileNotFoundError(zdb_path)\n",
    "if not os.path.exists(edf_path):\n",
    "    raise FileNotFoundError(edf_path)\n",
    "eeg_channel = MAPPING_OF_FILE_IDS_TO_CHANNEL_NAME[id]\n",
    "eeg = torch.from_numpy(read_raw_edf(edf_path).get_data(picks=[eeg_channel])[0]).float().reshape(-1,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = f'/home/andrew/sleep/models/gandalfs/gandalf_0/best_model.pt'\n",
    "from lib.models import Gandalf\n",
    "model = Gandalf()\n",
    "model.load_state_dict(torch.load(f=PATH_TO_MODEL,map_location='cpu'))\n",
    "DEVICE = 'cuda'\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class FeatureSet(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.len = len(X)\n",
    "        self.X = torch.cat([torch.zeros(4,5000),X,torch.zeros(4,5000)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx:idx+9].flatten()\n",
    "dataloader = DataLoader(dataset=FeatureSet(eeg),batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1620 [00:00<?, ?it/s]/home/andrew/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "100%|██████████| 1620/1620 [01:03<00:00, 25.41it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch.Tensor()\n",
    "    y_logits = torch.Tensor()\n",
    "    for Xi in tqdm(dataloader):\n",
    "        Xi = Xi.to(DEVICE)\n",
    "        logits = model(Xi)\n",
    "        y_logits = torch.cat([y_logits,torch.softmax(logits,dim=1).detach().cpu()])\n",
    "        y_pred = torch.cat([y_pred,torch.softmax(logits,dim=1).argmax(axis=1).detach().cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "        ..\n",
       "51818    2\n",
       "51819    2\n",
       "51820    2\n",
       "51821    2\n",
       "51822    2\n",
       "Name: 0, Length: 51823, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# y_pred = pd.DataFrame(y_pred.numpy()).astype(int)\n",
    "\n",
    "# y_pred[y_pred['0'] == 0] = 'P'\n",
    "# y_pred[y_pred['0'] == 1] = 'S'\n",
    "# y_pred[y_pred['0'] == 2] = 'W'\n",
    "# y_pred.to_csv(f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.csv',index=False) # write to file because inference takes time and you can resume here\n",
    "y_pred = pd.read_csv(f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51818</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51819</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51820</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51821</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51822</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51823 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      2\n",
       "1      2\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "...   ..\n",
       "51818  2\n",
       "51819  2\n",
       "51820  2\n",
       "51821  2\n",
       "51822  2\n",
       "\n",
       "[51823 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {'W':'Sleep-Wake', 'S':'Sleep-SWS', 'P':'Sleep-Paradoxical', 'X':''}\n",
    "offset = 10e7       #epoch time period\n",
    "csv_path = f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "try:\n",
    "    conn = sqlite3.connect(zdb_path)\n",
    "except Error as e:\n",
    "    print(e)\n",
    "cur = conn.cursor()\n",
    "\n",
    "#drop this table - creates issues\n",
    "query = \"DROP TABLE IF EXISTS temporary_scoring_marker;\"\n",
    "cur.execute(query)\n",
    "\n",
    "#get keyid of scoring\n",
    "query = \"SELECT MAX(id) FROM scoring_revision WHERE name='Machine Data'\"\n",
    "cur.execute(query)\n",
    "keyid = cur.fetchall()[0][0]\n",
    "\n",
    "#get starting point for scoring\n",
    "query = \"SELECT id FROM scoring_marker WHERE type LIKE 'Sleep%' AND key_id='\"+str(keyid)+\"';\"\n",
    "cur.execute(query)\n",
    "startid = cur.fetchall()[0][0]\n",
    "\n",
    "#get start time to crreate epochs\n",
    "query = 'SELECT starts_at FROM scoring_marker WHERE id = '+str(startid)+\";\"\n",
    "cur.execute(query)\n",
    "start_time = cur.fetchall()[0][0]\n",
    "stop_time = 0\n",
    "\n",
    "#delete first score before adding machine data\n",
    "query = \"DELETE FROM scoring_marker;\"\n",
    "cur.execute(query)\n",
    "\n",
    "#insert new epochs with scoring into the table\n",
    "for i in range(len(df)):\n",
    "    #calculate epoch\n",
    "    if i != 0:\n",
    "        start_time = stop_time\n",
    "    stop_time = start_time+offset\n",
    "\n",
    "    score = rename_dict[df.at[i,'0']]\n",
    "    #insert epoch\n",
    "    query = f\"\"\"\n",
    "            INSERT INTO scoring_marker \n",
    "            (starts_at, ends_at, notes, type, location, is_deleted, key_id)\n",
    "            VALUES \n",
    "            ({start_time}, {stop_time}, '', '{score}', '', 0, {keyid});\n",
    "            \"\"\" \n",
    "    cur.execute(query)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
