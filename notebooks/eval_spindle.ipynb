{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import *\n",
    "from lib.models import *\n",
    "from lib.ekyn import *\n",
    "from lib.env import *\n",
    "from lib.datasets import *\n",
    "def load_spindle_eeg_label_pair_2s(cohort='A',subject='1'):\n",
    "    # verify each 2 second epoch has all the same label\n",
    "    # all([all(yi[0]==yi) for yi in y])\n",
    "    if cohort == 'C':\n",
    "        fs = 200\n",
    "    else:\n",
    "        fs = 128\n",
    "    raw = read_raw_edf(f'../data/spindle/Cohort{cohort}/recordings/{cohort}{subject}.edf')\n",
    "    eeg = raw.get_data('EEG1').squeeze()\n",
    "    eeg = resample(eeg,86400*500)\n",
    "    X = torch.from_numpy(eeg.reshape(-1,5000)).float()\n",
    "    df = pd.read_csv(f'../data/spindle/Cohort{cohort}/scorings/{cohort}{subject}.csv',header=None)\n",
    "    cat = pd.Categorical(df[1])\n",
    "    cats = cat.categories\n",
    "    labels = np.array([[a]*2000 for a in list(cat.codes)]).flatten()\n",
    "    y = torch.from_numpy(labels.reshape(-1,1000)).mode(dim=1).values\n",
    "    if f'{cohort}{subject}' in ['D1','D2','D3','C1','C2','C3','C4','C5','C6','C7','C8']:\n",
    "        # ['1', 'n', 'r', 'w']\n",
    "        y[torch.where(y == 0)[0]] = 3\n",
    "        y[torch.where(y == 2)[0]] = 0\n",
    "        y[torch.where(y == 3)[0]] = 2\n",
    "    elif f'{cohort}{subject}' in ['D4','D5','D6']:\n",
    "        # ['n', 'r', 'w']\n",
    "        y[torch.where(y == 1)[0]] = 3\n",
    "        y[torch.where(y == 0)[0]] = 1\n",
    "        y[torch.where(y == 3)[0]] = 0\n",
    "    elif f'{cohort}{subject}' in ['A2','B1']:\n",
    "        # ['1', '2', '3', 'a', 'n', 'r', 'w']\n",
    "        y[torch.where(y == 0)[0]] = 6\n",
    "        y[torch.where(y == 1)[0]] = 4\n",
    "        y[torch.where(y == 2)[0]] = 5\n",
    "        y[torch.where(y == 3)[0]] = 5\n",
    "        y[torch.where(y == 4)[0]] = 1\n",
    "        y[torch.where(y == 5)[0]] = 0\n",
    "        y[torch.where(y == 6)[0]] = 2\n",
    "    else:\n",
    "        # ['1', '2', '3', 'n', 'r', 'w']\n",
    "        y[torch.where(y == 0)[0]] = 5\n",
    "        y[torch.where(y == 1)[0]] = 3\n",
    "        y[torch.where(y == 2)[0]] = 4\n",
    "        y[torch.where(y == 3)[0]] = 1\n",
    "        y[torch.where(y == 4)[0]] = 0\n",
    "        y[torch.where(y == 5)[0]] = 2\n",
    "    y = torch.nn.functional.one_hot(y.long()).float()\n",
    "    X = torch.cat([zeros(9//2,5000),X,zeros(9//2,5000)])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gandalf(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Frodo(n_features=5000,device=DEVICE).to(DEVICE)\n",
    "        self.lstm = nn.LSTM(16,32,bidirectional=True)\n",
    "        self.fc1 = nn.Linear(64,3)\n",
    "    def forward(self,x_2d,classification=True):\n",
    "        x_2d = x_2d.view(-1,9,1,5000)\n",
    "        x = torch.Tensor().to(DEVICE)\n",
    "        for t in range(x_2d.size(1)):\n",
    "            xi = self.encoder(x_2d[:,t,:,:],classification=False)\n",
    "            x = torch.cat([x,xi.unsqueeze(0)],dim=0)\n",
    "        out,_ = self.lstm(x)\n",
    "        if(classification):\n",
    "            x = self.fc1(out[-1])\n",
    "        else:\n",
    "            x = out[-1]\n",
    "        return x\n",
    "model = Gandalf()\n",
    "model.load_state_dict(torch.load(f'../spindle_gandalfs/gandalf_spindle_fold_00/best_model.pt'))\n",
    "model.to(DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "ids = ['A1','A2','A3','A4','B1','B2','B3','B4','C1','C2','C3','C4','C5','C6','C7','C8','D1','D2','D3','D4','D5','D6']\n",
    "test_id = ids[FOLD]\n",
    "print(test_id)\n",
    "ids.remove(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [load_spindle_eeg_label_pair(cohort=id[0],subject=id[1]) for id in [test_id]]\n",
    "Xs = [subject[0] for subject in subjects]\n",
    "ys = [subject[1] for subject in subjects]\n",
    "devloader = DataLoader(dataset=SSDataset(Xs,ys,range(8640)),batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,report,y_true,y_pred,y_logits = evaluate(devloader,model,criterion,DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences = []\n",
    "idx = y_logits.argmax(axis=1)\n",
    "for logit,idx in zip(y_logits,idx):\n",
    "    confidences.append(logit[idx].item())\n",
    "fig,axes = plt.subplots(ncols=1,nrows=4,figsize=(8.5,11),dpi=200,gridspec_kw={'height_ratios': [1,1,1,2]})\n",
    "lower = 1000\n",
    "upper = 1360\n",
    "\n",
    "# true label signal\n",
    "axes[0].plot(y_true[lower:upper],'black')\n",
    "axes[0].set_yticks(np.arange(3),labels=['P','S','W'])\n",
    "axes[0].set_ylabel('Stage')\n",
    "axes[0].text(200,1,'Reference',fontdict={'family': 'serif',\n",
    "        'color':  'darkred',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        })\n",
    "axes[0].spines[['right', 'top']].set_visible(False)\n",
    "axes[0].margins(.01,.01)\n",
    "\n",
    "# predicted label signal\n",
    "axes[1].plot(y_pred[lower:upper],'black')\n",
    "axes[1].set_yticks(np.arange(3),labels=['P','S','W'])\n",
    "axes[1].set_ylabel('Stage')\n",
    "axes[1].text(200,1,'Predicted',fontdict={'family': 'serif',\n",
    "        'color':  'darkred',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        })\n",
    "axes[1].spines[['right', 'top']].set_visible(False)\n",
    "axes[1].margins(.01,.01)\n",
    "\n",
    "# eeg signal\n",
    "axes[2].plot(Xs[0][lower+8:upper+8:5].flatten())\n",
    "axes[2].set_ylim([-.0002,.0002])\n",
    "axes[2].margins(0,0)\n",
    "axes[2].set_ylabel('microVolts')\n",
    "\n",
    "# predicted probability distribution\n",
    "axes[3].stackplot(torch.arange(len(y_logits[lower:upper])),y_logits[lower:upper].T)\n",
    "axes[3].plot(confidences[lower:upper],'black')\n",
    "axes[3].set_ylabel('Probability')\n",
    "axes[3].margins(0,0)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('out.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['A1','A2','A3','A4','B1','B2','B3','B4','C1','C2','C3','C4','C5','C6','C7','C8','D1','D2','D3','D4','D5','D6']\n",
    "FOLDS = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "all_metrics = pd.DataFrame()\n",
    "all_metrics_2s = pd.DataFrame()\n",
    "all_metrics_4s = pd.DataFrame()\n",
    "all_stats = pd.DataFrame()\n",
    "all_confidences = []\n",
    "stage_propotions = pd.DataFrame()\n",
    "recall_cm = torch.zeros((3,3))\n",
    "recall_cm_2s = torch.zeros((3,3))\n",
    "recall_cm_4s = torch.zeros((3,3))\n",
    "precision_cm = torch.zeros((3,3))\n",
    "precision_cm_2s = torch.zeros((3,3))\n",
    "precision_cm_4s = torch.zeros((3,3))\n",
    "for FOLD in FOLDS:\n",
    "    test_id = ids[FOLD]\n",
    "    print(test_id)\n",
    "    subjects = [load_spindle_eeg_label_pair(cohort=id[0],subject=id[1]) for id in [test_id]]\n",
    "    Xs = [subject[0] for subject in subjects]\n",
    "    ys = [subject[1] for subject in subjects]\n",
    "    testloader = DataLoader(dataset=SSDataset(Xs,ys,range(8640)),batch_size=32,shuffle=False)\n",
    "    model = Gandalf()\n",
    "    model.load_state_dict(torch.load(f'../spindle_gandalfs/gandalf_spindle_fold_{FOLD:02d}/best_model.pt',map_location='cpu'))\n",
    "    model.to(DEVICE)\n",
    "    loss,report,y_true,y_pred,y_logits = evaluate(testloader,model,criterion,DEVICE)\n",
    "\n",
    "    subjects = [load_spindle_eeg_label_pair_2s(cohort=id[0],subject=id[1]) for id in [test_id]]\n",
    "    Xs = [subject[0] for subject in subjects]\n",
    "    ys = [subject[1] for subject in subjects]\n",
    "    y_true_2s = ys[0]\n",
    "    y_true_2s = y_true_2s.argmax(axis=1)\n",
    "    y_pred_2s = y_pred.repeat(5,1).T.flatten()\n",
    "    report_2s = metrics(y_true_2s,y_pred_2s)\n",
    "    y_true_4s = y_true_2s.reshape(-1,2).mode(dim=1).values\n",
    "    y_pred_4s = y_pred_2s.reshape(-1,2).mode(dim=1).values\n",
    "    report_4s = metrics(y_true_4s,y_pred_4s)\n",
    "\n",
    "    confidences = []\n",
    "    idx = y_logits.argmax(axis=1)\n",
    "    for logit,idx in zip(y_logits,idx):\n",
    "        confidences.append(logit[idx].item())\n",
    "    all_confidences.append(torch.tensor(confidences).mean())\n",
    "    recall_cm += confusion_matrix(y_true=y_true,y_pred=y_pred,normalize='true')\n",
    "    recall_cm_2s += confusion_matrix(y_true=y_true_2s,y_pred=y_pred_2s,normalize='true')\n",
    "    recall_cm_4s += confusion_matrix(y_true=y_true_4s,y_pred=y_pred_4s,normalize='true')\n",
    "    precision_cm += confusion_matrix(y_true=y_true,y_pred=y_pred,normalize='pred')\n",
    "    precision_cm_2s += confusion_matrix(y_true=y_true_2s,y_pred=y_pred_2s,normalize='pred')\n",
    "    precision_cm_4s += confusion_matrix(y_true=y_true_4s,y_pred=y_pred_4s,normalize='pred')\n",
    "    all_metrics = pd.concat([all_metrics,pd.Series(report,name=f'{FOLD}')],axis=1)\n",
    "    all_metrics_2s = pd.concat([all_metrics_2s,pd.Series(report_2s,name=f'{FOLD}')],axis=1)\n",
    "    all_metrics_4s = pd.concat([all_metrics_4s,pd.Series(report_4s,name=f'{FOLD}')],axis=1)\n",
    "    stage_propotions = pd.concat([stage_propotions,pd.Series((torch.bincount(y_pred.long())/8640).tolist()+['Predicted'],name=f'{FOLD}')],axis=1)\n",
    "    stage_propotions = pd.concat([stage_propotions,pd.Series((torch.bincount(y_true.long())/8640).tolist()+['Reference'],name=f'{FOLD}')],axis=1)\n",
    "    df = pd.DataFrame(y_true)\n",
    "    df.loc[df[0] == 2,0] = 'W'\n",
    "    df.loc[df[0] == 1,0] = 'S'\n",
    "    df.loc[df[0] == 0,0] = 'P'\n",
    "    stats = get_bout_statistics_for_predictions(df[0]).reset_index().melt(id_vars='index')\n",
    "    stats['type'] = 'Reference'\n",
    "    all_stats = pd.concat([all_stats,stats],axis=1)\n",
    "    df = pd.DataFrame(y_pred)\n",
    "    df.loc[df[0] == 2,0] = 'W'\n",
    "    df.loc[df[0] == 1,0] = 'S'\n",
    "    df.loc[df[0] == 0,0] = 'P'\n",
    "    stats = get_bout_statistics_for_predictions(df[0]).reset_index().melt(id_vars='index')\n",
    "    stats['type'] = 'Predicted'\n",
    "    all_stats = pd.concat([all_stats,stats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_4s.T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((2 * recall_cm_4s * precision_cm_4s)/(recall_cm_4s + precision_cm_4s))/len(FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_2s.T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame([c.item() for c in all_confidences],columns=['c'])\n",
    "c['f1'] = all_metrics.T['f1'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n",
    "sns.set_style('whitegrid')\n",
    "fig,axes = plt.subplots(nrows=2,ncols=2,figsize=(8,8),dpi=200)\n",
    "sns.boxplot(data=stage_propotions.T.melt(id_vars=3),x='variable',y='value',hue=3,ax=axes[1,1])\n",
    "sns.boxplot(data=all_metrics.T.melt(),y='value',x='variable',ax=axes[0,0])\n",
    "sns.heatmap(recall_cm/len(FOLDS),annot=True,fmt='.2f',cbar=False,cmap='Blues',ax=axes[1,0])\n",
    "sns.regplot(data=c,x='c',y='f1',ax=axes[0,1])\n",
    "\n",
    "axes[0,0].set_ylim(.5,1)\n",
    "axes[1,1].set_ylim(-.05,.6)\n",
    "axes[0,0].set_ylabel('Score')\n",
    "axes[0,0].set_xlabel('Metric (averaged over n=16 folds)')\n",
    "axes[1,0].set_xticklabels(labels=['P','S','W'])\n",
    "axes[1,0].set_yticklabels(labels=['P','S','W'])\n",
    "axes[1,1].set_xticklabels(labels=['P','S','W'])\n",
    "axes[0,1].set_xlabel('Average Confidence')\n",
    "axes[0,1].set_ylabel('macro f1-score')\n",
    "axes[1,0].set_xlabel('Predicted')\n",
    "axes[1,0].set_ylabel('Reference')\n",
    "axes[1,1].set_xlabel('Stage')\n",
    "axes[1,1].set(ylabel='Proportion of total recording time')\n",
    "axes[1,1].legend()\n",
    "axes[0,1].set_xticks([])\n",
    "axes[0,1].set_yticks([])\n",
    "plt.margins(x=0,y=0)\n",
    "plt.savefig('spindle_grid.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(all_stats.to_numpy().reshape(-1,4))\n",
    "tmp[2] = tmp[2].astype(float)\n",
    "fig,axes = plt.subplots(nrows=3,ncols=1,figsize=(8.5,11),dpi=200,gridspec_kw={'height_ratios': [1,1,1]},sharex=True)\n",
    "sns.violinplot(data=tmp[tmp[1] == 'P'],x=0,y=2,hue=3,split=True,ax=axes[0])\n",
    "sns.violinplot(data=tmp[tmp[1] == 'S'],x=0,y=2,hue=3,split=True,ax=axes[1])\n",
    "sns.violinplot(data=tmp[tmp[1] == 'W'],x=0,y=2,hue=3,split=True,ax=axes[2])\n",
    "axes[0].set_ylabel('Paradoxical (seconds)')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].legend()\n",
    "axes[1].set_ylabel('Slow-wave (seconds)')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].get_legend().remove()\n",
    "axes[2].set_ylabel('Wakefulness (seconds)')\n",
    "axes[2].set_xlabel('')\n",
    "axes[2].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n",
    "sns.set_style('whitegrid')\n",
    "fig,axes = plt.subplots(nrows=3,ncols=3,figsize=(9,9),dpi=200)\n",
    "\n",
    "axes[0,0].set_title('Total Bout Duration')\n",
    "axes[0,1].set_title('Average Bout Duration')\n",
    "axes[0,2].set_title('Number of Bouts')\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'total') & (tmp[1] == 'P')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[0,0])\n",
    "axes[0,0].set_xlim([0,150])\n",
    "axes[0,0].set_ylim([0,150])\n",
    "axes[0,0].set_xlabel('')\n",
    "axes[0,0].set_ylabel('Reference (paradoxical)')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'total') & (tmp[1] == 'S')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[0,1])\n",
    "\n",
    "axes[0,1].set_xlim([300,900])\n",
    "axes[0,1].set_ylim([300,900])\n",
    "axes[0,1].set_xlabel('')\n",
    "axes[0,1].set_ylabel('')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'total') & (tmp[1] == 'W')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[0,2])\n",
    "\n",
    "axes[0,2].set_xlim([500,1200])\n",
    "axes[0,2].set_ylim([500,1200])\n",
    "axes[0,2].set_xlabel('')\n",
    "axes[0,2].set_ylabel('')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'average') & (tmp[1] == 'P')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[1,0])\n",
    "\n",
    "axes[1,0].set_xlim([0,150])\n",
    "axes[1,0].set_ylim([0,150])\n",
    "axes[1,0].set_xlabel('')\n",
    "axes[1,0].set_ylabel('Reference (slow wave)')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'average') & (tmp[1] == 'S')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[1,1])\n",
    "\n",
    "axes[1,1].set_xlim([50,350])\n",
    "axes[1,1].set_ylim([50,350])\n",
    "axes[1,1].set_xlabel('')\n",
    "axes[1,1].set_ylabel('')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'average') & (tmp[1] == 'W')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[1,2])\n",
    "\n",
    "axes[1,2].set_xlim([100,500])\n",
    "axes[1,2].set_ylim([100,500])\n",
    "axes[1,2].set_xlabel('')\n",
    "axes[1,2].set_ylabel('')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'counts') & (tmp[1] == 'P')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[2,0])\n",
    "\n",
    "axes[2,0].set_xlim([0,160])\n",
    "axes[2,0].set_ylim([0,160])\n",
    "axes[2,0].set_xlabel('Predicted')\n",
    "axes[2,0].set_ylabel('Reference (wakefulness)')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'counts') & (tmp[1] == 'S')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[2,1])\n",
    "\n",
    "axes[2,1].set_xlim([100,400])\n",
    "axes[2,1].set_ylim([100,400])\n",
    "axes[2,1].set_xlabel('Predicted')\n",
    "axes[2,1].set_ylabel('')\n",
    "\n",
    "sns.regplot(data=pd.DataFrame(tmp[(tmp[0] == 'counts') & (tmp[1] == 'W')][2].to_numpy().reshape(-1,2),columns=['Reference','Predicted']),x='Reference',y='Predicted',ax=axes[2,2])\n",
    "\n",
    "axes[2,2].set_xlim([100,400])\n",
    "axes[2,2].set_ylim([100,400])\n",
    "axes[2,2].set_xlabel('Predicted')\n",
    "axes[2,2].set_ylabel('')\n",
    "\n",
    "plt.margins(x=0,y=0)\n",
    "plt.savefig('reg.svg',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
