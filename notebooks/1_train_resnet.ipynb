{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib.ekyn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import bincount\n",
    "from lib.utils import plot_eeg_and_labels\n",
    "from lib.models import MLP\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from lib.utils import evaluate\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report\n",
    "from lib.env import DEVICE\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = get_ekyn_ids()\n",
    "train_idx,test_idx = train_test_split(idx,test_size=.25,random_state=0)\n",
    "print(len(train_idx),len(test_idx))\n",
    "train_idx = train_idx\n",
    "test_idx = test_idx\n",
    "print(train_idx,test_idx)\n",
    "\n",
    "X,y = load_eeg_label_pairs(ids=train_idx)\n",
    "print(X.shape,y.shape)\n",
    "print(bincount(y.argmax(axis=1)))\n",
    "plot_eeg_and_labels(X,y.argmax(axis=1),start=0,duration=50)\n",
    "trainloader = DataLoader(TensorDataset(X,y),batch_size=512,shuffle=True)\n",
    "X,y = load_eeg_label_pairs(ids=test_idx)\n",
    "print(X.shape,y.shape)\n",
    "print(bincount(y.argmax(axis=1)))\n",
    "plot_eeg_and_labels(X,y.argmax(axis=1),start=0,duration=50)\n",
    "devloader = DataLoader(TensorDataset(X,y),batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu\n",
    "class BLOCK(nn.Module):\n",
    "    def __init__(self,n_features,in_feature_maps,out_feature_maps) -> None:\n",
    "        super().__init__()\n",
    "        self.in_feature_maps = in_feature_maps\n",
    "        self.out_feature_maps = out_feature_maps\n",
    "        if in_feature_maps != out_feature_maps:\n",
    "            self.c1 = nn.Conv1d(in_channels=in_feature_maps,out_channels=out_feature_maps,kernel_size=3,stride=2,padding=1)\n",
    "        else:\n",
    "            self.c1 = nn.Conv1d(in_channels=in_feature_maps,out_channels=out_feature_maps,kernel_size=3,padding='same')\n",
    "        self.ln1 = nn.LayerNorm(normalized_shape=(n_features))\n",
    "        self.c2 = nn.Conv1d(in_channels=out_feature_maps,out_channels=out_feature_maps,kernel_size=3,padding='same')\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=(n_features))\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_channels=in_feature_maps,out_channels=out_feature_maps,kernel_size=1,stride=2)\n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        x = self.c1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = relu(x)\n",
    "        if self.in_feature_maps != self.out_feature_maps:\n",
    "            x = x + self.downsample(identity)\n",
    "        else:\n",
    "            x = x + identity\n",
    "        return x\n",
    "\n",
    "class MODEL(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.c1 = nn.Conv1d(in_channels=1,out_channels=4,kernel_size=10,stride=2,padding=4)\n",
    "        self.ln1 = nn.LayerNorm(normalized_shape=(2500))\n",
    "        self.mp1 = nn.MaxPool1d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.block1 = BLOCK(n_features=1250,in_feature_maps=4,out_feature_maps=4)        \n",
    "        self.block2 = BLOCK(n_features=1250,in_feature_maps=4,out_feature_maps=4)\n",
    "\n",
    "        self.block3 = BLOCK(n_features=625,in_feature_maps=4,out_feature_maps=8)        \n",
    "        self.block4 = BLOCK(n_features=625,in_feature_maps=8,out_feature_maps=8)\n",
    "\n",
    "        self.block5 = BLOCK(n_features=313,in_feature_maps=8,out_feature_maps=16)        \n",
    "        self.block6 = BLOCK(n_features=313,in_feature_maps=16,out_feature_maps=16)        \n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AvgPool1d(kernel_size=157),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(16,3),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(32,3)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x.reshape(-1,1,5000)\n",
    "        x = self.c1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp1(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = MODEL()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=3e-4)\n",
    "params = sum([p.flatten().size()[0] for p in list(model.parameters())])\n",
    "print(\"Params: \",params)\n",
    "lossi = []\n",
    "trainlossi = []\n",
    "devlossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi,yi = next(iter(trainloader))\n",
    "model(Xi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(DEVICE)\n",
    "for epoch in tqdm(range(100)):\n",
    "    for Xi,yi in trainloader:\n",
    "        Xi,yi = Xi.to(DEVICE),yi.to(DEVICE)\n",
    "        logits = model(Xi)\n",
    "        loss = criterion(logits,yi)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossi.append(loss.item())\n",
    "    if epoch % 10 == 0:\n",
    "        plt.plot(torch.tensor(lossi[:len(lossi) - len(lossi)%10]).view(-1,10).mean(axis=1))\n",
    "        plt.savefig('loss.jpg')\n",
    "        plt.close()\n",
    "\n",
    "        loss,_,_,_,_ = evaluate(dataloader=trainloader,model=model,criterion=criterion,DEVICE=DEVICE)\n",
    "        trainlossi.append(loss)\n",
    "        loss,_,_,_,_ = evaluate(dataloader=devloader,model=model,criterion=criterion,DEVICE=DEVICE)\n",
    "        devlossi.append(loss)\n",
    "        print(loss)\n",
    "\n",
    "        plt.plot(trainlossi)\n",
    "        plt.plot(devlossi)\n",
    "        plt.savefig('dev.jpg')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.tensor(lossi[:len(lossi) - len(lossi)%10]).view(-1,10).mean(axis=1)[-1])\n",
    "# best dev loss : 0.38113740152782866\n",
    "# best dev loss : 0.37259188603471827\n",
    "# best dev loss : 0.3583390266806991\n",
    "# best dev loss : 0.3157875328152268\n",
    "# best dev loss : 0.299214439590772\n",
    "# 0.2897572392666781\n",
    "# 0.2731048853309066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "Xi,yi = next(iter(trainloader))\n",
    "\n",
    "fig,ax = plt.subplots(nrows=len(model.c1.weight),ncols=2,figsize=(8,10))\n",
    "for i,kernel in enumerate(model.c1.weight.squeeze().detach()):\n",
    "    ax[i,0].plot(kernel)\n",
    "for i,kernel in enumerate(model.c1(Xi.reshape(-1,1,5000)).detach()[0]):\n",
    "    ax[i,1].plot(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,report,y_true,y_pred,y_logits = evaluate(dataloader=trainloader,model=model,criterion=criterion,DEVICE=DEVICE)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,report,y_true,y_pred,y_logits = evaluate(dataloader=devloader,model=model,criterion=criterion,DEVICE=DEVICE)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true')\n",
    "print(classification_report(y_true,y_pred))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_eeg_label_pairs(ids=test_idx[:1])\n",
    "print(X.shape,y.shape)\n",
    "print(bincount(y.argmax(axis=1)))\n",
    "plot_eeg_and_labels(X,y.argmax(axis=1),start=0,duration=50)\n",
    "testloader = DataLoader(TensorDataset(X,y),batch_size=512,shuffle=False)\n",
    "import matplotlib.pyplot as plt\n",
    "loss,report,y_true,y_pred,y_logits = evaluate(dataloader=testloader,model=model,criterion=criterion,DEVICE=DEVICE)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true')\n",
    "print(classification_report(y_true,y_pred))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "start = 190\n",
    "duration = 200\n",
    "fig, ax = plt.subplots(nrows=2,ncols=1,figsize=(16,5),dpi=200)\n",
    "\n",
    "ax[1].plot(X[start:start+duration].flatten(),'black',linewidth=.2)\n",
    "colors = ['red','green','blue']\n",
    "epochs = []\n",
    "for i in range(duration):\n",
    "    stage = int(y.argmax(axis=1)[start+i])\n",
    "    ax[1].fill_between([i*5000, (i+1)*5000], y1=-.0003, y2=.0003, color=colors[stage], alpha=0.3)\n",
    "    epochs.append(i*5000+2500)\n",
    "\n",
    "red_patch = patches.Patch(color='red', alpha=0.5, label='Paradoxical')\n",
    "green_patch = patches.Patch(color='green', alpha=0.5, label='Slow-wave')\n",
    "blue_patch = patches.Patch(color='blue', alpha=0.5, label='Wakefulness')\n",
    "ax[1].set_ylim([-.0003,.0003])\n",
    "ax[1].margins(0,0)\n",
    "plt.legend(handles=[red_patch, green_patch,blue_patch],loc='upper left', bbox_to_anchor=(1.04, 1),\n",
    "        fancybox=True, shadow=True, ncol=1)\n",
    "plt.xlabel('epoch (index)')\n",
    "ax[1].set_ylabel('potential energy (Volts)')\n",
    "ax[1].set_xticks(epochs[::int(duration/20)],range(duration)[::int(duration/20)]);\n",
    "\n",
    "ax[0].stackplot(torch.linspace(0,duration-1,duration),y_logits[start:start+duration,0],y_logits[start:start+duration,1],y_logits[start:start+duration,2],colors=['#FF000080','#00FF0080','#0000FF80'])\n",
    "ax[0].margins(0,0)\n",
    "ax[0].set_xticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
