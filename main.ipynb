{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models import ResNet\n",
    "from lib.datasets import Dataset2p0\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from lib.utils import cms,test_evaluation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = ResNet().to(device)\n",
    "\n",
    "params = sum([p.flatten().size()[0] for p in list(model.parameters())])\n",
    "print(\"Params: \",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'w1'\n",
    "trainloader = DataLoader(Dataset2p0(dir=f'{data_dir}/train/',labels=f'{data_dir}/y_train.pt'),batch_size=64,shuffle=True)\n",
    "devloader = DataLoader(Dataset2p0(dir=f'{data_dir}/dev/',labels=f'{data_dir}/y_dev.pt'),batch_size=64,shuffle=True)\n",
    "testloader = DataLoader(Dataset2p0(dir=f'{data_dir}/test/',labels=f'{data_dir}/y_test.pt'),batch_size=64,shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for i in range(50):\n",
    "    for (X_tr,y_tr) in tqdm(trainloader):\n",
    "        X_tr,y_tr = X_tr.to(device),y_tr.to(device)\n",
    "        logits = model(X_tr)\n",
    "        loss = criterion(logits,y_tr)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)\n",
    "print(torch.tensor(lossi).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(lossi[100:len(lossi) - len(lossi)%20]).view(-1,20).mean(axis=1))\n",
    "print(torch.tensor(lossi[100:len(lossi) - len(lossi)%20]).view(-1,20).mean(axis=1)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation(trainloader,model,criterion)\n",
    "# .22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation(devloader,model,criterion)\n",
    "#.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = torch.load(f'{data_dir}/holdout_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdoutloader = DataLoader(TensorDataset(X,y),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from lib.utils import get_bout_statistics_for_predictions\n",
    "import numpy as np\n",
    "loss,y_true,y_pred = test_evaluation(holdoutloader,model,criterion)\n",
    "pred_expert = np.array(y_pred.detach().cpu()).copy()\n",
    "print(\"Experting\")\n",
    "for j in range(len(pred_expert)-2):\n",
    "    if((pred_expert[j:j+2]==np.array([2,0])).all()):\n",
    "        pred_expert[j+1] = 2\n",
    "for j in range(len(pred_expert)-2):\n",
    "    if(pred_expert[j+1] != pred_expert[j] and pred_expert[j+1] != pred_expert[j+2]):\n",
    "        pred_expert[j+1] = pred_expert[j]\n",
    "df = pd.DataFrame([y_true.numpy(),y_pred.detach().cpu().numpy(),pred_expert],index=['true','pred','expert']).T\n",
    "\n",
    "df.loc[df['true'] == 2,'true'] = 'W'\n",
    "df.loc[df['true'] == 1,'true'] = 'S'\n",
    "df.loc[df['true'] == 0,'true'] = 'P'\n",
    "df.loc[df['pred'] == 2,'pred'] = 'W'\n",
    "df.loc[df['pred'] == 1,'pred'] = 'S'\n",
    "df.loc[df['pred'] == 0,'pred'] = 'P'\n",
    "df.loc[df['expert'] == 2,'expert'] = 'W'\n",
    "df.loc[df['expert'] == 1,'expert'] = 'S'\n",
    "df.loc[df['expert'] == 0,'expert'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bout_statistics_for_predictions(df['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bout_statistics_for_predictions(df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(data_frame=df)\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms(y_true=y_true,y_pred=pred_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
