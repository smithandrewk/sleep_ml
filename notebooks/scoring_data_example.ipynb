{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH_TO_DIRECTORY_OF_DATA_TO_SCORE = f'/home/andrew/sleep/data_to_score'\n",
    "MAPPING_OF_FILE_IDS_TO_CHANNEL_NAME = {\n",
    "    \"SPARC-10-M\":\"EEG 1\", \n",
    "    \"SPARC-11-M\":\"EEG 1\",\n",
    "    \"SPARC-12-M\":\"EEG 1\",\n",
    "    \"SPARC-13-M\":\"EEG 1\",\n",
    "    \"SPARC-14-M\":\"EEG 1\",\n",
    "    \"SPARC-15-M\":\"EEG 1\",\n",
    "    \"SPARC-17-M\":\"EEG 2\",\n",
    "    \"SPARC-18-M\":\"EEG 1\",\n",
    "    \"SPARC-2-F\":\"EEG 1\",\n",
    "    \"SPARC-4-F\":\"EEG 1\",\n",
    "    \"SPARC-5-F\":\"Channel-2\",\n",
    "    \"SPARC-8-F\":\"Channel-10\",\n",
    "    \"SPARC-9-F\":\"Channel-2\",\n",
    "    \"SPARC-10-F\":\"Channel-50\",\n",
    "    \"SPARC-11-F\":\"Channel-18\",\n",
    "    \"SPARC-12-F\":\"Channel-42\",\n",
    "    \"SPARC-13-F\":\"EEG 1\",\n",
    "    \"SPARC-14-F\":\"EEG 1\",\n",
    "    \"SPARC-15-F\":\"EEG 1\",\n",
    "    \"SPARC-16-F\":\"EEG 2\"\n",
    "}\n",
    "IDS = sorted(list(set([id.split('.')[0] for id in os.listdir(PATH_TO_DIRECTORY_OF_DATA_TO_SCORE)])))\n",
    "print(IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.io import read_raw_edf\n",
    "import torch\n",
    "id = IDS[1]\n",
    "print(id)\n",
    "zdb_path = f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.zdb'\n",
    "edf_path = f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.edf'\n",
    "if not os.path.exists(zdb_path):\n",
    "    raise FileNotFoundError(zdb_path)\n",
    "if not os.path.exists(edf_path):\n",
    "    raise FileNotFoundError(edf_path)\n",
    "eeg_channel = MAPPING_OF_FILE_IDS_TO_CHANNEL_NAME[id]\n",
    "eeg = torch.from_numpy(read_raw_edf(edf_path).get_data(picks=[eeg_channel])[0]).float().reshape(-1,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = f'/home/andrew/sleep/models/gandalfs/gandalf_0/best_model.pt'\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu\n",
    "DEVICE = 'cuda'\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_feature_maps,out_feature_maps,n_features) -> None:\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(in_feature_maps,out_feature_maps,kernel_size=8,padding='same',bias=False)\n",
    "        self.bn1 = nn.LayerNorm((out_feature_maps,n_features),elementwise_affine=False)\n",
    "\n",
    "        self.c2 = nn.Conv1d(out_feature_maps,out_feature_maps,kernel_size=5,padding='same',bias=False)\n",
    "        self.bn2 = nn.LayerNorm((out_feature_maps,n_features),elementwise_affine=False)\n",
    "\n",
    "        self.c3 = nn.Conv1d(out_feature_maps,out_feature_maps,kernel_size=3,padding='same',bias=False)\n",
    "        self.bn3 = nn.LayerNorm((out_feature_maps,n_features),elementwise_affine=False)\n",
    "\n",
    "        self.c4 = nn.Conv1d(in_feature_maps,out_feature_maps,1,padding='same',bias=False)\n",
    "        self.bn4 = nn.LayerNorm((out_feature_maps,n_features),elementwise_affine=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        x = self.c1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = relu(x)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = relu(x)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = relu(x)\n",
    "\n",
    "        identity = self.c4(identity)\n",
    "        identity = self.bn4(identity)\n",
    "\n",
    "        x = x+identity\n",
    "        x = relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Frodo(nn.Module):\n",
    "    \"\"\"\n",
    "    the little wanderer\n",
    "    \"\"\"\n",
    "    def __init__(self,n_features,device='cuda') -> None:\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.block1 = ResidualBlock(1,8,n_features)\n",
    "        self.block2 = ResidualBlock(8,16,n_features)\n",
    "        self.block3 = ResidualBlock(16,16,n_features)\n",
    "\n",
    "        self.gap = nn.AvgPool1d(kernel_size=n_features)\n",
    "        self.fc1 = nn.Linear(in_features=16,out_features=3)\n",
    "    def forward(self,x,classification=True):\n",
    "        x = x.view(-1,1,self.n_features)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.gap(x)\n",
    "        if(classification):\n",
    "            x = self.fc1(x.squeeze())\n",
    "            return x\n",
    "        else:\n",
    "            return x.squeeze()\n",
    "        \n",
    "class Gandalf(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Frodo(n_features=5000,device=DEVICE).to(DEVICE)\n",
    "        self.lstm = nn.LSTM(16,32,bidirectional=True)\n",
    "        self.fc1 = nn.Linear(64,3)\n",
    "    def forward(self,x_2d,classification=True):\n",
    "        x_2d = x_2d.view(-1,9,1,5000)\n",
    "        x = torch.Tensor().to(DEVICE)\n",
    "        for t in range(x_2d.size(1)):\n",
    "            xi = self.encoder(x_2d[:,t,:,:],classification=False)\n",
    "            x = torch.cat([x,xi.unsqueeze(0)],dim=0)\n",
    "        out,_ = self.lstm(x)\n",
    "        if(classification):\n",
    "            x = self.fc1(out[-1])\n",
    "        else:\n",
    "            x = out[-1]\n",
    "        return x\n",
    "model = Gandalf()\n",
    "model.load_state_dict(torch.load(f=PATH_TO_MODEL,map_location='cpu'))\n",
    "DEVICE = 'cuda'\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class FeatureSet(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.len = len(X)\n",
    "        self.X = torch.cat([torch.zeros(4,5000),X,torch.zeros(4,5000)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx:idx+9].flatten()\n",
    "dataloader = DataLoader(dataset=FeatureSet(eeg),batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch.Tensor()\n",
    "    y_logits = torch.Tensor()\n",
    "    for Xi in tqdm(dataloader):\n",
    "        Xi = Xi.to(DEVICE)\n",
    "        logits = model(Xi)\n",
    "        y_logits = torch.cat([y_logits,torch.softmax(logits,dim=1).detach().cpu()])\n",
    "        y_pred = torch.cat([y_pred,torch.softmax(logits,dim=1).argmax(axis=1).detach().cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_pred = pd.DataFrame(y_pred.numpy()).astype(int)\n",
    "\n",
    "y_pred[y_pred[0] == 0] = 'P'\n",
    "y_pred[y_pred[0] == 1] = 'S'\n",
    "y_pred[y_pred[0] == 2] = 'W'\n",
    "csv_path = f'{PATH_TO_DIRECTORY_OF_DATA_TO_SCORE}/{id}.csv'\n",
    "\n",
    "y_pred.to_csv(csv_path,index=False) # write to file because inference takes time and you can resume here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "rename_dict = {'W':'Sleep-Wake', 'S':'Sleep-SWS', 'P':'Sleep-Paradoxical', 'X':''}\n",
    "offset = 10e7#epoch time period\n",
    "\n",
    "y_pred = pd.read_csv(csv_path)\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(zdb_path)\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "# get recording start stop\n",
    "cur = conn.cursor()\n",
    "query = \"SELECT value FROM internal_property WHERE key='RecordingStart'\"\n",
    "cur.execute(query)\n",
    "result = cur.fetchall()\n",
    "recording_start = int(result[0][0])\n",
    "query = \"SELECT value FROM internal_property WHERE key='RecordingStop'\"\n",
    "cur.execute(query)\n",
    "result = cur.fetchall()\n",
    "recording_stop = int(result[0][0])\n",
    "length_ns = recording_stop - recording_start # ns\n",
    "length_s = length_ns * 1e-7 # s\n",
    "hh = length_s // 3600\n",
    "mm = (length_s % 3600) // 60\n",
    "ss = ((length_s % 3600) % 60)\n",
    "print(hh,mm,ss,length_s)\n",
    "print(recording_start)\n",
    "print(recording_stop)\n",
    "\n",
    "#drop this table - creates issues\n",
    "query = \"DROP TABLE IF EXISTS temporary_scoring_marker;\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "cur.execute(query)\n",
    "\n",
    "tables = [table[0] for table in cur.fetchall()]\n",
    "\n",
    "if 'scoring_revision' not in tables:\n",
    "    query = \"CREATE TABLE scoring_revision (id INTEGER PRIMARY KEY, name TEXT, is_deleted INTEGER(1), tags TEXT, version INTEGER(8), owner TEXT, date_created INTEGER(8));\"\n",
    "    cur.execute(query)\n",
    "\n",
    "if 'scoring_marker' not in tables:\n",
    "    query = \"CREATE TABLE scoring_marker (id INTEGER PRIMARY KEY, starts_at INTEGER(8), ends_at INTEGER(8), notes TEXT, type TEXT, location TEXT, is_deleted INTEGER(1), key_id INTEGER);\"\n",
    "    cur.execute(query)\n",
    "\n",
    "if 'scoring_comment' not in tables:\n",
    "    query = \"CREATE TABLE scoring_comment (id INTEGER PRIMARY KEY, category TEXT, key TEXT, value TEXT);\"\n",
    "    cur.execute(query)\n",
    "\n",
    "if 'scoring_key' not in tables:\n",
    "    query = \"CREATE TABLE scoring_key (id INTEGER PRIMARY KEY, date_created INTEGER(8), name TEXT, owner TEXT, type TEXT);\"\n",
    "    cur.execute(query)\n",
    "\n",
    "if 'scoring_revision_to_comment' not in tables:\n",
    "    query = \"CREATE TABLE scoring_revision_to_comment (revision_id INTEGER(8), comment_id INTEGER(8));\"\n",
    "    cur.execute(query)\n",
    "\n",
    "if 'scoring_revision_to_key' not in tables:\n",
    "    query = \"CREATE TABLE scoring_revision_to_key (revision_id INTEGER(8), key_id INTEGER(8));\"\n",
    "    cur.execute(query)\n",
    "\n",
    "# delete first score before adding machine data\n",
    "query = \"DELETE FROM scoring_marker;\"\n",
    "cur.execute(query)\n",
    "\n",
    "#delete first score before adding machine data\n",
    "query = \"DELETE FROM scoring_revision;\"\n",
    "cur.execute(query)\n",
    "\n",
    "#delete first score before adding machine data\n",
    "query = \"DELETE FROM scoring_key;\"\n",
    "cur.execute(query)\n",
    "\n",
    "#delete first score before adding machine data\n",
    "query = \"DELETE FROM scoring_revision_to_key;\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = f\"\"\"\n",
    "    INSERT INTO scoring_revision \n",
    "    (name, is_deleted, version, date_created)\n",
    "    VALUES \n",
    "    ('LSTM', 0, 0, {recording_start});\n",
    "    \"\"\" \n",
    "cur.execute(query)\n",
    "\n",
    "query = f\"\"\"\n",
    "    INSERT INTO scoring_key \n",
    "    (date_created, type)\n",
    "    VALUES \n",
    "    ({recording_start},'Automatic');\n",
    "    \"\"\" \n",
    "cur.execute(query)\n",
    "\n",
    "query = f\"\"\"\n",
    "    INSERT INTO scoring_revision_to_key \n",
    "    (revision_id, key_id)\n",
    "    VALUES \n",
    "    (1,1);\n",
    "    \"\"\" \n",
    "cur.execute(query)\n",
    "\n",
    "#get keyid of scoring\n",
    "query = \"SELECT MAX(id) FROM scoring_revision WHERE name='LSTM'\"\n",
    "cur.execute(query)\n",
    "keyid = cur.fetchall()[0][0]\n",
    "\n",
    "start_time = recording_start - (recording_start % 100000000)\n",
    "stop_time = 0\n",
    "# #insert new epochs with scoring into the table\n",
    "for i in range(len(y_pred)):\n",
    "    #calculate epoch\n",
    "    if i != 0:\n",
    "        start_time = stop_time\n",
    "    stop_time = start_time+offset\n",
    "\n",
    "    score = rename_dict[y_pred.at[i,'0']]\n",
    "    #insert epoch\n",
    "    query = f\"\"\"\n",
    "            INSERT INTO scoring_marker \n",
    "            (starts_at, ends_at, notes, type, location, is_deleted, key_id)\n",
    "            VALUES \n",
    "            ({start_time}, {stop_time}, '', '{score}', '', 0, {keyid});\n",
    "            \"\"\" \n",
    "    cur.execute(query)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
