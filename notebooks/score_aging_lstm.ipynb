{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:  10286\n"
     ]
    }
   ],
   "source": [
    "from lib.models import *\n",
    "from lib.datasets import Dataset2p0\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from lib.utils import cms,test_evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from lib.utils import get_bout_statistics_for_predictions\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from lib.utils import load_raw_by_path\n",
    "from lib.utils import load_raw_by_path\n",
    "from torch import nn\n",
    "from torch.nn.functional import batch_norm,relu\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lib.models import ResNet as MODEL\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "device = 'cuda'\n",
    "model = BigPapa().to(device)\n",
    "model.load_state_dict(torch.load('84.pt',map_location='cuda'))\n",
    "\n",
    "params = sum([p.flatten().size()[0] for p in list(model.parameters())])\n",
    "print(\"Params: \",params)\n",
    "\n",
    "EEG_1 = [1,8,14,15,16]\n",
    "EEG_2 = [3,4,5,6,7,9,10,11,12,13,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1672/1672 [00:41<00:00, 40.06it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 40.24it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 40.10it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 39.95it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 40.01it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 40.02it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 40.31it/s]\n",
      "100%|██████████| 1672/1672 [00:41<00:00, 40.33it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 40.06it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 40.18it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 39.81it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 39.99it/s]\n",
      "100%|██████████| 1632/1632 [00:41<00:00, 39.77it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 39.89it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 40.26it/s]\n",
      "100%|██████████| 1632/1632 [00:40<00:00, 40.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for fileindex in range(1,18):\n",
    "    if(fileindex==2):\n",
    "        continue\n",
    "    raw = load_raw_by_path(f'../data/raw_aging_edf/22-AGING-{fileindex}.edf').get_data(picks=['EEG','EMG'])\n",
    "    if(fileindex in EEG_1):\n",
    "        eeg = raw[0]\n",
    "    elif(fileindex in EEG_2):\n",
    "        eeg = raw[1]\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    X = torch.from_numpy(eeg.reshape(-1,5000)).float()\n",
    "\n",
    "    # center, stretch\n",
    "    X = (X - X.mean(axis=1,keepdim=True))/X.std(axis=1,keepdim=True)\n",
    "    if(X.isinf().any()):\n",
    "        print(\"inf\")\n",
    "    windowsize = 9\n",
    "    # only works for odd windows, puts label at center\n",
    "    cat = [X[:-(windowsize-1)]]\n",
    "    for i in range(1,(windowsize-1)):\n",
    "        cat.append(X[i:i-(windowsize-1)])\n",
    "    cat.append(X[(windowsize-1):])\n",
    "    X = torch.cat(cat,axis=1).float()\n",
    "    dataloader = DataLoader(TensorDataset(X),batch_size=16)\n",
    "    y_pred = torch.Tensor().cuda()\n",
    "    model.eval()\n",
    "    for (X_test) in tqdm(dataloader):\n",
    "        X_test = X_test[0].to(device)\n",
    "        logits = model(X_test)\n",
    "        y_pred = torch.cat([y_pred,torch.softmax(logits,dim=1).argmax(axis=1)])\n",
    "    pred_expert = y_pred.cpu().numpy()\n",
    "\n",
    "    for j in range(len(pred_expert)-2):\n",
    "        if(pred_expert[j+1] != pred_expert[j] and pred_expert[j+1] != pred_expert[j+2]):\n",
    "            pred_expert[j+1] = pred_expert[j]\n",
    "    df = pd.DataFrame([pred_expert]).T\n",
    "    df[df[0] == 0] = 'P'\n",
    "    df[df[0] == 1] = 'S'\n",
    "    df[df[0] == 2] = 'W'\n",
    "    df.to_csv(f'aging_pred/{fileindex}.csv',index=False)\n",
    "\n",
    "    rename_dict = {'W':'Sleep-Wake', 'S':'Sleep-SWS', 'P':'Sleep-Paradoxical', 'X':''}\n",
    "    offset = 10e7       #epoch time period\n",
    "    csv_filename = f'aging_pred/{fileindex}.csv'\n",
    "    zdb_filename = f'aging_zdb/22-AGING-{fileindex}.zdb'\n",
    "\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    try:\n",
    "        conn = sqlite3.connect(zdb_filename)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #drop this table - creates issues\n",
    "    query = \"DROP TABLE IF EXISTS temporary_scoring_marker;\"\n",
    "    cur.execute(query)\n",
    "\n",
    "    #get keyid of scoring\n",
    "    query = \"SELECT MAX(id) FROM scoring_revision WHERE name='Machine Data'\"\n",
    "    cur.execute(query)\n",
    "    keyid = cur.fetchall()[0][0]\n",
    "\n",
    "    #get starting point for scoring\n",
    "    query = \"SELECT id FROM scoring_marker WHERE type LIKE 'Sleep%' AND key_id='\"+str(keyid)+\"';\"\n",
    "    cur.execute(query)\n",
    "    startid = cur.fetchall()[0][0]\n",
    "\n",
    "    #get start time to crreate epochs\n",
    "    query = 'SELECT starts_at FROM scoring_marker WHERE id = '+str(startid)+\";\"\n",
    "    cur.execute(query)\n",
    "    start_time = cur.fetchall()[0][0]\n",
    "    stop_time = 0\n",
    "\n",
    "    #delete first score before adding machine data\n",
    "    query = \"DELETE FROM scoring_marker;\"\n",
    "    cur.execute(query)\n",
    "\n",
    "    #insert new epochs with scoring into the table\n",
    "    for i in range(len(df)):\n",
    "        #calculate epoch\n",
    "        if i != 0:\n",
    "            start_time = stop_time\n",
    "        stop_time = start_time+offset\n",
    "\n",
    "        score = rename_dict[df.at[i,'0']]\n",
    "        #insert epoch\n",
    "        query = f\"\"\"\n",
    "                INSERT INTO scoring_marker \n",
    "                (starts_at, ends_at, notes, type, location, is_deleted, key_id)\n",
    "                VALUES \n",
    "                ({start_time}, {stop_time}, '', '{score}', '', 0, {keyid});\n",
    "                \"\"\" \n",
    "        cur.execute(query)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
