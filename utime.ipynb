{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import *\n",
    "from lib.models import *\n",
    "from lib.ekyn import *\n",
    "from lib.env import *\n",
    "from lib.datasets import *\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "class Windowset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx],self.y[idx])\n",
    "def evaluate_utime(dataloader,model,criterion):\n",
    "    with torch.no_grad():\n",
    "        y_true = torch.Tensor()\n",
    "        y_pred = torch.Tensor()\n",
    "        y_logits = torch.Tensor()\n",
    "        loss_total = 0\n",
    "        for (Xi,yi) in dataloader:\n",
    "            yi = yi.flatten(0,1)\n",
    "            y_true = torch.cat([y_true,yi.argmax(axis=1).flatten()])\n",
    "            logits = model(Xi).transpose(1,2).flatten(0,1)\n",
    "\n",
    "            loss = criterion(logits,yi)\n",
    "            loss_total += loss.item()\n",
    "            \n",
    "            y_logits = torch.cat([y_logits,torch.softmax(logits,dim=1).detach().cpu()])\n",
    "            y_pred = torch.cat([y_pred,torch.softmax(logits,dim=1).argmax(axis=1).detach().cpu()])\n",
    "    return y_true,y_pred,y_logits,loss_total/len(dataloader)\n",
    "def load_dataloader(id='A1-1',condition='Vehicle',shuffle=True):\n",
    "    X,y = load_eeg_label_pair(id=id,condition=condition)\n",
    "    fs = 100\n",
    "    X = torch.from_numpy(resample(X.flatten(),86400*fs)).reshape(-1,fs*10)\n",
    "    scaler = RobustScaler()\n",
    "    X = torch.from_numpy(scaler.fit_transform(X.reshape(-1,1)).reshape(-1,fs*10)).float()\n",
    "    X = X.reshape(-1,10000)\n",
    "    y = y.reshape(-1,10,3)\n",
    "    dataloader = DataLoader(Windowset(X,y),batch_size=32,shuffle=shuffle)\n",
    "    return dataloader\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_features, max_pool, max_pool_kernel_size) -> None:\n",
    "        super().__init__()\n",
    "        self.max_pool = max_pool\n",
    "        self.c1 = nn.Conv1d(in_channels=in_channels,out_channels=out_channels,kernel_size=5,stride=1,dilation=2,padding='same')\n",
    "        self.ln1 = nn.LayerNorm((out_channels,n_features))\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.c2 = nn.Conv1d(in_channels=out_channels,out_channels=out_channels,kernel_size=5,stride=1,dilation=2,padding='same')\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=(out_channels,n_features))\n",
    "        self.r2 = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool1d(kernel_size=max_pool_kernel_size)\n",
    "    def forward(self,x):\n",
    "        x = self.c1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.r1(x)\n",
    "        residual = self.c2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.r2(x)\n",
    "        if self.max_pool:\n",
    "            return residual,self.mp1(x)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, scale_factor, in_channels, out_channels, n_features, kernel_size) -> None:\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor,mode='nearest')\n",
    "        self.c1 = nn.Conv1d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,stride=1,dilation=2,padding='same')\n",
    "        self.ln1 = nn.LayerNorm((out_channels,n_features * scale_factor))\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.c2 = nn.Conv1d(in_channels=out_channels * 2,out_channels=out_channels,kernel_size=kernel_size,stride=1,dilation=2,padding='same')\n",
    "        self.ln2 = nn.LayerNorm((out_channels,n_features * scale_factor))\n",
    "        self.r2 = nn.ReLU()\n",
    "        self.c3 = nn.Conv1d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,stride=1,dilation=2,padding='same')\n",
    "        self.ln3 = nn.LayerNorm((out_channels,n_features * scale_factor))\n",
    "        self.r3 = nn.ReLU()\n",
    "    def forward(self, x, residual):\n",
    "        x = self.upsample(x)\n",
    "        x = self.c1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.r1(x)\n",
    "        x = torch.cat([x,residual],dim=1)\n",
    "        x = self.c2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.r2(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.ln3(x)\n",
    "        x = self.r3(x)\n",
    "        return x\n",
    "class UTIME(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder1 = Encoder(in_channels=1,out_channels=8,n_features=10000,max_pool=True,max_pool_kernel_size=10)\n",
    "        self.encoder2 = Encoder(in_channels=8,out_channels=8,n_features=1000,max_pool=True,max_pool_kernel_size=8)\n",
    "        self.encoder3 = Encoder(in_channels=8,out_channels=8,n_features=125,max_pool=False,max_pool_kernel_size=None)\n",
    "\n",
    "        self.decoder1 = Decoder(scale_factor=8, in_channels=8, out_channels=8, n_features=125, kernel_size=8)\n",
    "        self.decoder2 = Decoder(scale_factor=10, in_channels=8, out_channels=8, n_features=1000, kernel_size=10)\n",
    "\n",
    "        self.c = nn.Conv1d(in_channels=8,out_channels=3,kernel_size=1,stride=1)\n",
    "        self.ap = nn.AvgPool1d(kernel_size=1000)\n",
    "        self.c1 = nn.Conv1d(in_channels=3,out_channels=3,kernel_size=1,stride=1)\n",
    "    def forward(self,x,features=False):\n",
    "        x = x.view(-1,1,10000)\n",
    "        # print(x.shape)\n",
    "        a,x = self.encoder1(x)\n",
    "        # print(f'{x.shape} a: {a.shape}')\n",
    "        b,x = self.encoder2(x)\n",
    "        # print(f'{x.shape} b: {b.shape}')\n",
    "        # print(x.shape)\n",
    "        x = self.encoder3(x)\n",
    "        # print(x.shape)\n",
    "        x = self.decoder1(x,b)\n",
    "        # print(x.shape)\n",
    "        x = self.decoder2(x,a)\n",
    "        # print(x.shape)\n",
    "        x = self.c(x)\n",
    "        # print(x.shape)\n",
    "        x = self.ap(x)\n",
    "        # print(x.shape)\n",
    "        x = self.c1(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1,3,10)\n",
    "        return x\n",
    "def load_eeg_label_pairs_resampled_scaled(ids=['A1-1']):\n",
    "    old_fs = 500\n",
    "    fs = 100\n",
    "    X_train = Tensor()\n",
    "    y_train = Tensor()\n",
    "    for id in ids:\n",
    "        for condition in ['Vehicle', 'PF']:\n",
    "            Xi,yi = load_eeg_label_pair(id,condition)\n",
    "            Xi = Xi.flatten()\n",
    "            Xi = torch.from_numpy(resample(Xi,int(Xi.shape[0]/old_fs)*fs)).reshape(-1,fs*10)\n",
    "            scaler = RobustScaler()\n",
    "            Xi = torch.from_numpy(scaler.fit_transform(Xi.reshape(-1,1)).reshape(-1,fs*10)).float()\n",
    "            Xi = Xi.reshape(-1,10000)\n",
    "            yi = yi.reshape(-1,10,3)\n",
    "            X_train = cat([X_train, Xi])\n",
    "            y_train = cat([y_train, yi])\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(Windowset(*load_eeg_label_pairs_resampled_scaled(ids=get_ekyn_ids()[:6])),batch_size=32,shuffle=True)\n",
    "devloader = DataLoader(Windowset(*load_eeg_label_pairs_resampled_scaled(ids=get_ekyn_ids()[-4:])),batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:  890383\n"
     ]
    }
   ],
   "source": [
    "model = UTIME()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "params = sum([p.flatten().size()[0] for p in list(model.parameters())])\n",
    "print(\"Params: \",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [02:31<00:00,  2.14it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  6.97it/s]\n",
      "100%|██████████| 324/324 [02:27<00:00,  2.19it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.18it/s]\n",
      "100%|██████████| 324/324 [02:28<00:00,  2.18it/s]\n",
      "100%|██████████| 216/216 [00:29<00:00,  7.30it/s]\n",
      "100%|██████████| 324/324 [02:24<00:00,  2.24it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.07it/s]\n",
      "100%|██████████| 324/324 [02:28<00:00,  2.18it/s]\n",
      "100%|██████████| 216/216 [00:31<00:00,  6.91it/s]\n",
      "100%|██████████| 324/324 [02:28<00:00,  2.19it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.10it/s]\n",
      "100%|██████████| 324/324 [02:29<00:00,  2.17it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.00it/s]\n",
      "100%|██████████| 324/324 [02:28<00:00,  2.18it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.08it/s]\n",
      "100%|██████████| 324/324 [02:27<00:00,  2.19it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.09it/s]\n",
      "100%|██████████| 324/324 [02:27<00:00,  2.19it/s]\n",
      "100%|██████████| 216/216 [00:30<00:00,  7.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_lossi = []\n",
    "dev_lossi = []\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_total = 0\n",
    "    for X,y in tqdm(trainloader):\n",
    "        logits = model(X).transpose(1,2).flatten(0,1)\n",
    "        loss = criterion(logits,y.flatten(0,1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_total += loss.item()\n",
    "    train_lossi.append(train_total/len(trainloader))\n",
    "    model.eval()\n",
    "    dev_total = 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in tqdm(devloader):\n",
    "            logits = model(X).transpose(1,2).flatten(0,1)\n",
    "            loss = criterion(logits,y.flatten(0,1))\n",
    "            dev_total += loss.item()\n",
    "    dev_lossi.append(dev_total/len(devloader))\n",
    "    plt.plot(train_lossi)\n",
    "    plt.plot(dev_lossi)\n",
    "    plt.savefig('loss.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testloader = load_dataloader(id=,condition='Vehicle',shuffle=False)\n",
    "y_true,y_pred,y_logits,loss = evaluate_utime(devloader,model,criterion)\n",
    "cm_grid(y_true,y_pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = get_ekyn_ids()\n",
    "for id in ids:\n",
    "    print(id)\n",
    "    testloader = load_dataloader(id=id,condition='Vehicle',shuffle=False)\n",
    "    y_true,y_pred,y_logits,loss = evaluate_utime(testloader,model,criterion)\n",
    "    cm_grid(y_true,y_pred)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,4),dpi=200)\n",
    "plt.stackplot(range(8640),y_logits.T.detach())\n",
    "plt.plot(y_true)\n",
    "plt.savefig('out.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(pd.DataFrame([y_true,y_pred]).T)\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.softmax(logits,dim=1).argmax(axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_grid(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_true = torch.Tensor()\n",
    "    y_pred = torch.Tensor()\n",
    "    y_logits = torch.Tensor()\n",
    "    y_features = torch.Tensor()\n",
    "    loss_total = 0\n",
    "    for (Xi,yi) in testloader:\n",
    "        y_true = torch.cat([y_true,yi.argmax(axis=1).flatten()])\n",
    "\n",
    "        logits = model(Xi)\n",
    "        loss = criterion(logits,yi)\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        # y_logits = torch.cat([y_logits,torch.softmax(logits,dim=1).detach().cpu()])\n",
    "        y_pred = torch.cat([y_pred,torch.softmax(logits,dim=1).argmax(axis=1).flatten().detach().cpu()])\n",
    "        # y_features = torch.cat([y_features,model(Xi,classification=False).detach().cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_grid(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
