{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ekyn import *\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu\n",
    "from lib.models import *\n",
    "from lib.deep_learning_utils import evaluate\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report,f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ekyn': array(['F1-0', 'B3-1', 'A4-0', 'F1-1', 'E2-1', 'C4-1', 'F5-1', 'E4-0',\n",
      "       'B1-0', 'A1-0', 'C1-0', 'E4-1'], dtype='<U4'), 'snezana_mice': array(['21-WK-15', '21-WT-1', '21-WK-18', '21-WT-10', '21-WK-6',\n",
      "       '21-HET-4', '21-KO-11', '21-WK-17', '21-WK-13', '386', '354',\n",
      "       '21-KO-4', '381', '21-WK-11', '21-KO-12', '21-HET-2', '21-WK-16',\n",
      "       '21-KO-2', '21-WT-7', '21-KO-6', '21-WT-8', '21-HET-5', '21-KO-10',\n",
      "       '21-WK-10', '21-KO-3', '21-WT-13', '21-WT-4', '21-WT-9', '21-WK-8',\n",
      "       '21-HET-10', '21-KO-1', '429', '21-WK-1', '21-HET-3', '21-KO-9',\n",
      "       '21-WK-5', '21-KO-7', '21-KO-5', '21-HET-7', '21-WK-9', '382',\n",
      "       '21-HET-12', '21-HET-1', '378', '21-WT-5', '21-WT-2'], dtype='<U9')}\n",
      "{'ekyn': array(['A1-1', 'C4-0', 'D1-0', 'E1-0'], dtype='<U4'), 'snezana_mice': array(['21-WK-4', '21-WK-3', '21-WT-12', '21-WK-12', '21-HET-9',\n",
      "       '21-HET-11', '21-WK-2', '21-WT-3', '21-KO-8', '21-WT-6',\n",
      "       '21-HET-13', '21-HET-8'], dtype='<U9')}\n",
      "16 58\n",
      "2532 training batches 777 testing batches\n",
      "1296384 training samples 397824 testing samples\n",
      "3601.07 training hours 1105.07 testing hours\n"
     ]
    }
   ],
   "source": [
    "ekyn_ids = get_ekyn_ids()\n",
    "snezana_mice_ids = get_snezana_mice_ids()\n",
    "\n",
    "ekyn_ids = np.array(ekyn_ids)\n",
    "snezana_mice_ids = np.array(snezana_mice_ids)\n",
    "\n",
    "ekyn_train_ids,ekyn_test_ids = train_test_split(ekyn_ids,test_size=.2,shuffle=True,random_state=0)\n",
    "snezana_mice_train_ids,snezana_mice_test_ids = train_test_split(snezana_mice_ids,test_size=.2,shuffle=True,random_state=0)\n",
    "\n",
    "train_ids = {'ekyn':ekyn_train_ids,'snezana_mice':snezana_mice_train_ids}\n",
    "test_ids  = {'ekyn':ekyn_test_ids,'snezana_mice':snezana_mice_test_ids}\n",
    "batch_size = 512\n",
    "\n",
    "from torch.utils.data import DataLoader,ConcatDataset\n",
    "trainloader = DataLoader(\n",
    "        dataset=ConcatDataset(\n",
    "        [EpochedDataset(id=id,condition=condition,robust=True,downsampled=True) for id in train_ids['ekyn'] for condition in CONDITIONS] \n",
    "        + [EpochedDataset(id=id,snezana_mice=True) for id in train_ids['snezana_mice']]\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    )\n",
    "\n",
    "testloader = DataLoader(\n",
    "        dataset=ConcatDataset(\n",
    "        [EpochedDataset(id=id,condition=condition,robust=True,downsampled=True) for id in test_ids['ekyn'] for condition in CONDITIONS] \n",
    "        + [EpochedDataset(id=id,snezana_mice=True) for id in test_ids['snezana_mice']]\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    )\n",
    "print(train_ids)\n",
    "print(test_ids)\n",
    "print(len(ekyn_ids),len(snezana_mice_ids))\n",
    "print(f'{len(trainloader)} training batches {len(testloader)} testing batches')\n",
    "print(f'{len(trainloader)*batch_size} training samples {len(testloader)*batch_size} testing samples')\n",
    "print(f'{len(trainloader)*batch_size*10/3600:.2f} training hours {len(testloader)*batch_size*10/3600:.2f} testing hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetv2(block=ResBlockv2,widthi=[2,4,8,16],depthi=[2,2,2,2],n_output_neurons=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlossi = []\n",
    "testlossi = []\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_dev_loss = torch.inf\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/sleep/sleep_ml/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sleep/sleep_ml/env/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/sleep/sleep_ml/env/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/sleep/sleep_ml/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sleep/sleep_ml/env/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    model.train()\n",
    "    for Xi,yi in trainloader:\n",
    "        Xi,yi = Xi.to('cuda'),yi.to('cuda')\n",
    "        logits = model(Xi)\n",
    "        loss = criterion(logits,yi)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainlossi.append(loss.item())\n",
    "        # plt.figure()\n",
    "        # plt.plot(trainlossi)\n",
    "        # plt.savefig(f'lossi.jpg')\n",
    "        # plt.close()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_total = 0\n",
    "        for Xi,yi in testloader:\n",
    "            Xi,yi = Xi.to('cuda'),yi.to('cuda')\n",
    "            logits = model(Xi)\n",
    "            loss = criterion(logits,yi)\n",
    "            loss_total += loss.item()\n",
    "        testlossi.append(loss_total/len(testloader))\n",
    "    \n",
    "    if testlossi[-1] < best_dev_loss:\n",
    "        best_dev_loss = testlossi[-1]\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    print(best_dev_loss)\n",
    "    plt.figure()\n",
    "    plt.plot(torch.linspace(0,len(testlossi),len(trainlossi)),trainlossi)\n",
    "    plt.plot(torch.linspace(0,len(testlossi),len(testlossi) + 1),[trainlossi[0]] + testlossi)\n",
    "    plt.savefig('loss.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dev_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(8,4))\n",
    "loss,y_true,y_pred = evaluate(dataloader=trainloader,model=model,criterion=criterion,device='cuda')\n",
    "print(loss)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',ax=axes[0],colorbar=False)\n",
    "axes[0].set_title(f'trainf1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')\n",
    "loss,y_true,y_pred = evaluate(dataloader=testloader,model=model,criterion=criterion,device='cuda')\n",
    "print(loss)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',ax=axes[1],colorbar=False)\n",
    "axes[1].set_title(f'testf1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')\n",
    "# first block 4\n",
    "# 0.15651415670436988 \n",
    "# 0.17776457286082847\n",
    "# first block 8\n",
    "# 0.14261297114022264\n",
    "# 0.17632858462388454\n",
    "# first block 16\n",
    "# 0.12881732295086315\n",
    "# 0.1683129257734678\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
