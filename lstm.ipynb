{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : generator\n",
    "from lib.ekyn import *\n",
    "from lib.env import *\n",
    "from sage.utils import *\n",
    "from sage.models import *\n",
    "from time import time\n",
    "import datetime\n",
    "import copy\n",
    "import os\n",
    "from sage.models import Dumbledore\n",
    "from lib.ekyn import *\n",
    "\n",
    "experiment_group_id = 'lstm'\n",
    "hyperparameters = {\n",
    "    'wd':1e-2,\n",
    "    'lr':3e-4,\n",
    "    'batch_size':2048,\n",
    "    'robust':False,\n",
    "    'norm':'batch',\n",
    "    'dropout':.1,\n",
    "    'stem_kernel_size':3,\n",
    "    'widthi':[4,8,16,32],\n",
    "    'depthi':[1,1,1,1],\n",
    "    'patience':100,\n",
    "    'scheduler_patience':50,\n",
    "    'epochs':500,\n",
    "    'sequence_length':21,\n",
    "    'encoder_experiment_name':f'2024_14_08_16_04_12',\n",
    "    'hidden_size':64,\n",
    "    'num_layers':1,\n",
    "    'frozen_encoder':True\n",
    "}\n",
    "\n",
    "trainloader,testloader = get_sequenced_dataloaders(batch_size=hyperparameters['batch_size'],sequence_length=hyperparameters['sequence_length'])\n",
    "model = Dumbledore(encoder_experiment_name=f'{EXPERIMENTS_PATH}/{hyperparameters[\"encoder_experiment_name\"]}',sequence_length=hyperparameters['sequence_length'],hidden_size=hyperparameters['hidden_size'],num_layers=hyperparameters['num_layers'],dropout=hyperparameters['dropout'],frozen_encoder=hyperparameters['frozen_encoder'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=hyperparameters['lr'],weight_decay=hyperparameters['wd'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=hyperparameters['scheduler_patience'])\n",
    "\n",
    "state = {\n",
    "    'start_time':datetime.datetime.now().strftime(\"%Y_%d_%m_%H_%M_%S\"),\n",
    "    'experiment_group_id':experiment_group_id,\n",
    "    'execution_time':0,\n",
    "    'device':'cuda',\n",
    "    'trainlossi':[],\n",
    "    'testlossi':[],\n",
    "    'best_dev_loss':torch.inf,\n",
    "    'model':model,\n",
    "    'scheduler':scheduler,\n",
    "    'criterion':criterion,\n",
    "    'optimizer':optimizer,\n",
    "    'best_model_wts':copy.deepcopy(model.state_dict()),\n",
    "}\n",
    "\n",
    "for key in hyperparameters:\n",
    "    state[key] = hyperparameters[key]\n",
    "\n",
    "last_time = time()\n",
    "\n",
    "os.makedirs(f'{EXPERIMENTS_PATH}/{state[\"start_time\"]}')\n",
    "\n",
    "for state in train(state,trainloader,testloader):\n",
    "    plot_loss(state,EXPERIMENTS_PATH)\n",
    "    state['execution_time'] = (state['execution_time'] + (time() - last_time))/2\n",
    "    last_time = time()\n",
    "    torch.save(state, f'{EXPERIMENTS_PATH}/{state[\"start_time\"]}/state.pt')\n",
    "torch.save(state, f'{EXPERIMENTS_PATH}/{state[\"start_time\"]}/state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay,f1_score\n",
    "\n",
    "best_model = copy.deepcopy(state['model'])\n",
    "best_model.load_state_dict(state['best_model_wts'])\n",
    "loss,y_true,y_pred = evaluate(dataloader=testloader,model=best_model,criterion=criterion,device='cuda')\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',colorbar=False)\n",
    "plt.title(f'f1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainloader,testloader = get_dataloaders(train_data,test_data)\n",
    "loss,y_true,y_pred = evaluate_sigmoid(dataloader=testloader,model=best_model,criterion=state['criterion'],device='cuda')\n",
    "f1 = f1_score(y_true,y_pred,average=\"macro\")\n",
    "print(f1)\n",
    "df.loc[experiment.name,'best_dev_f1'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lib.ekyn import *\n",
    "\n",
    "ekyn_ids = get_ekyn_ids()\n",
    "train_ids,test_ids = train_test_split(ekyn_ids,test_size=.2,shuffle=True,random_state=0)\n",
    "print(train_ids,test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in test_ids:\n",
    "    dataloader = get_epoched_dataloader_for_ids(ids=[id])\n",
    "    loss,y_true,y_pred = evaluate(dataloader=dataloader,model=model,criterion=criterion,device='cuda')\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',colorbar=False)\n",
    "    plt.title(f'f1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(8,4))\n",
    "loss,y_true,y_pred = evaluate(dataloader=trainloader,model=model,criterion=criterion,device='cuda')\n",
    "print(loss)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',ax=axes[0],colorbar=False)\n",
    "axes[0].set_title(f'trainf1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')\n",
    "loss,y_true,y_pred = evaluate(dataloader=testloader,model=model,criterion=criterion,device='cuda')\n",
    "print(loss)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',ax=axes[1],colorbar=False)\n",
    "axes[1].set_title(f'testf1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "for id in test_ids:\n",
    "    X,y = load_ekyn_pt_robust(id=id,condition='Vehicle',downsampled=True)\n",
    "    std,mean = torch.std_mean(X[torch.where(y.argmax(axis=1) == 1)[0]],dim=1)\n",
    "    sns.ecdfplot(std,linewidth=2,label=id)\n",
    "\n",
    "# df_long = df.melt()\n",
    "# df_long[['id','condition']] = df_long.variable.str.split('_',expand=True)\n",
    "# sns.ecdfplot(df_long[df_long.condition == 'Vehicle'],x='value',hue='id',linestyle='-')\n",
    "# sns.ecdfplot(df_long[df_long.condition == 'PF'],x='value',hue='id',linestyle='--')\n",
    "# std,mean = torch.std_mean(eeg,dim=1)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim([0,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
