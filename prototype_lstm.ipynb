{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ekyn import get_ekyn_ids,load_ekyn_pt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,ConcatDataset\n",
    "import math\n",
    "from torch import nn\n",
    "from lib.models import RegNet\n",
    "from torch.nn.functional import relu\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lib.datasets import EpochedDataset,SequencedDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "CONFIG = {\n",
    "    'WINDOW_SIZE':5000,\n",
    "    'BATCH_SIZE':64,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'DEVICE':'cuda',\n",
    "    'SEQUENCE_LENGTH':5\n",
    "}\n",
    "\n",
    "train_idx,test_idx = train_test_split(get_ekyn_ids(),test_size=.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(ConcatDataset([SequencedDataset(idx=idx,condition=condition,sequence_length=CONFIG['SEQUENCE_LENGTH']) for idx in train_idx for condition in ['Vehicle','PF']]),batch_size=CONFIG['BATCH_SIZE'],shuffle=True)\n",
    "devloader = DataLoader(ConcatDataset([SequencedDataset(idx=idx,condition=condition,sequence_length=CONFIG['SEQUENCE_LENGTH']) for idx in test_idx for condition in ['Vehicle','PF']]),batch_size=CONFIG['BATCH_SIZE'],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 0, depth 1\n",
      "1250\n",
      "block 0 8 8\n",
      "stage 1, depth 2\n",
      "625\n",
      "block 1 8 16\n",
      "625\n",
      "block 1 16 16\n",
      "stage 2, depth 4\n",
      "313\n",
      "block 2 16 32\n",
      "313\n",
      "block 2 32 32\n",
      "313\n",
      "block 2 32 32\n",
      "313\n",
      "block 2 32 32\n",
      "stage 3, depth 1\n",
      "157\n",
      "block 3 32 64\n",
      "Model is freezing encoder\n"
     ]
    }
   ],
   "source": [
    "from lib.models import Dumbledore\n",
    "import json\n",
    "from lib.models import RegNetY\n",
    "class Dumbledore(nn.Module):\n",
    "    def __init__(self,encoder_path,sequence_length,hidden_dim=8,frozen=True,embedding=False,layers=1) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder_path = encoder_path\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frozen = frozen\n",
    "        self.embedding = embedding\n",
    "        self.layers = layers\n",
    "        self.encoder = self.get_encoder()\n",
    "        if self.embedding:\n",
    "            self.latent_dim = self.ENCODER_CONFIG['WIDTHI'][-1]\n",
    "        else:\n",
    "            self.latent_dim = 3\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim,num_layers=self.layers,bidirectional=True,batch_first=True,dropout=.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2,3)\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x,return_embedding=self.embedding)\n",
    "        x = x.view(-1,self.sequence_length,self.latent_dim)\n",
    "        o,(h,c) = self.lstm(x)\n",
    "        x = self.fc1(o[:,-1])\n",
    "        return x\n",
    "    def get_encoder(self):\n",
    "        with open(f'{self.encoder_path}/config.json') as f:\n",
    "            self.ENCODER_CONFIG = json.load(f)\n",
    "        encoder = RegNetY(depth=self.ENCODER_CONFIG['DEPTHI'],width=self.ENCODER_CONFIG['WIDTHI'],stem_kernel_size=self.ENCODER_CONFIG['STEM_KERNEL_SIZE'])\n",
    "        encoder.load_state_dict(torch.load(f'{self.encoder_path}/best.f1.pt'))\n",
    "        if self.frozen:\n",
    "            print(\"Model is freezing encoder\")\n",
    "            for p in encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        return encoder\n",
    "\n",
    "model = Dumbledore(encoder_path=f'projects/6',sequence_length=CONFIG['SEQUENCE_LENGTH'],hidden_dim=16,layers=3,embedding=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=CONFIG['LEARNING_RATE'])\n",
    "model.to(CONFIG['DEVICE']);\n",
    "criterion.to(CONFIG['DEVICE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [04:00<01:43, 34.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_loop,development_loop\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)):\n\u001b[0;32m----> 8\u001b[0m     loss,f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDEVICE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     trainlossi\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     10\u001b[0m     trainf1\u001b[38;5;241m.\u001b[39mappend(f1)\n",
      "File \u001b[0;32m~/sleep/sleep_ml/lib/utils.py:444\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, trainloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    442\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    443\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m--> 444\u001b[0m     loss_tr_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    445\u001b[0m     y_pred\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39msoftmax(logits,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m    446\u001b[0m y_true \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(y_true)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainlossi = []\n",
    "trainf1 = []\n",
    "devlossi = []\n",
    "devf1 = []\n",
    "model.train()\n",
    "from lib.utils import training_loop,development_loop\n",
    "for i in tqdm(range(10)):\n",
    "    loss,f1 = training_loop(model=model,trainloader=trainloader,criterion=criterion,optimizer=optimizer,device=CONFIG['DEVICE'])\n",
    "    trainlossi.append(loss)\n",
    "    trainf1.append(f1)\n",
    "\n",
    "    loss,f1 = development_loop(model=model,devloader=devloader,criterion=criterion,device=CONFIG['DEVICE'])\n",
    "    devlossi.append(loss)\n",
    "    devf1.append(f1)\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(20,4))\n",
    "    ax[0].plot(trainlossi)\n",
    "    ax[0].plot(devlossi)\n",
    "    ax[1].plot(trainf1)\n",
    "    ax[1].plot(devf1)\n",
    "    plt.savefig('loss.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import evaluate\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report\n",
    "\n",
    "loss,report,y_true,y_pred,y_logits = evaluate(dataloader=devloader,model=model,criterion=criterion,DEVICE=CONFIG['DEVICE'])\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true')\n",
    "print(classification_report(y_true,y_pred))\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
