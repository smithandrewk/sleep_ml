{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lib.utils import load_raw_by_path\n",
    "from torch import nn\n",
    "from torch.nn.functional import batch_norm,relu\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "EEG_1 = [1,8,14,15,16]\n",
    "EEG_2 = [3,4,5,6,7,9,10,11,12,13,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(15000,128)\n",
    "        self.fc2 = nn.Linear(128,3)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = softmax(pred,dim=1).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experting\n"
     ]
    }
   ],
   "source": [
    "pred_expert = np.array(pred.detach().cpu()).copy()\n",
    "print(\"Experting\")\n",
    "for j in range(len(pred_expert)-2):\n",
    "    if((pred_expert[j:j+2]==np.array([2,0])).all()):\n",
    "        pred_expert[j+1] = 2\n",
    "for j in range(len(pred_expert)-2):\n",
    "    if(pred_expert[j+1] != pred_expert[j] and pred_expert[j+1] != pred_expert[j+2]):\n",
    "        pred_expert[j+1] = pred_expert[j]\n",
    "df = pd.DataFrame(pred_expert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    0.604134\n",
      "W    0.395006\n",
      "P    0.000860\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df[0].value_counts(normalize=True))\n",
    "df[df[0] == 0] = 'P'\n",
    "df[df[0] == 1] = 'S'\n",
    "df[df[0] == 2] = 'W'\n",
    "df.to_csv(f'pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.604134\n",
      "W    0.395006\n",
      "P    0.000860\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/17 [00:05<01:26,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.600321\n",
      "W    0.397473\n",
      "P    0.002205\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3/17 [00:10<00:47,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.710324\n",
      "W    0.288817\n",
      "P    0.000860\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4/17 [00:16<00:53,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.660611\n",
      "W    0.338790\n",
      "P    0.000598\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [00:21<00:54,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.570532\n",
      "W    0.427861\n",
      "P    0.001607\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [00:27<00:52,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "W    0.545862\n",
      "S    0.452904\n",
      "P    0.001233\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:32<00:49,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.734582\n",
      "W    0.264858\n",
      "P    0.000561\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8/17 [00:37<00:45,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.637475\n",
      "W    0.361479\n",
      "P    0.001047\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [00:42<00:41,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.533300\n",
      "W    0.465896\n",
      "P    0.000804\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [00:48<00:36,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "W    0.500287\n",
      "S    0.496687\n",
      "P    0.003026\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11/17 [00:54<00:32,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "W    0.522462\n",
      "S    0.476389\n",
      "P    0.001149\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [00:59<00:26,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.675884\n",
      "W    0.323044\n",
      "P    0.001072\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 13/17 [01:05<00:21,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.537704\n",
      "W    0.460419\n",
      "P    0.001877\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14/17 [01:10<00:16,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.672360\n",
      "W    0.325533\n",
      "P    0.002106\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [01:16<00:11,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "S    0.534181\n",
      "W    0.464708\n",
      "P    0.001111\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [01:22<00:05,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "Experting\n",
      "W    0.541611\n",
      "S    0.456589\n",
      "P    0.001800\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:28<00:00,  5.21s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = torch.load('model_1100.pt')\n",
    "# checkpoint = torch.load('model_106_0.3201.pt')\n",
    "# model = checkpoint['model_class']\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "dists = []\n",
    "for i in tqdm(range(1,18)):\n",
    "    if i==2:\n",
    "        continue\n",
    "    raw = load_raw_by_path(f'data/aging/22-AGING-{i}.edf').get_data(picks=['EEG','EMG'])\n",
    "    if(i in EEG_1):\n",
    "        eeg = raw[0]\n",
    "    elif(i in EEG_2):\n",
    "        eeg = raw[1]\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    del raw\n",
    "    eeg = torch.from_numpy(eeg.reshape(-1,5000))\n",
    "    X = torch.cat([eeg[:-2],eeg[1:-1],eeg[2:]],axis=1).float()\n",
    "    print(\"Centering\")\n",
    "    # eeg_centered = eeg - eeg.mean(axis=1).reshape(-1,1)\n",
    "    del eeg\n",
    "    # std = eeg_centered.std(axis=1)\n",
    "    # std[np.where(std==0)[0]] = 1\n",
    "    # eeg_norm = eeg_centered/std.reshape(-1,1)\n",
    "    # del eeg_centered\n",
    "    # del std\n",
    "    # X = torch.from_numpy(eeg_norm.reshape(-1,1,5000)).float()\n",
    "    # del eeg_norm\n",
    "    # print(X.isinf().any())\n",
    "    # X = X[:,:,::10]\n",
    "    y_pred = softmax(model(X.cuda()),dim=1).argmax(axis=1)\n",
    "    del X\n",
    "    pred_expert = np.array(y_pred.detach().cpu()).copy()\n",
    "    del y_pred\n",
    "    print(\"Experting\")\n",
    "    for j in range(len(pred_expert)-2):\n",
    "        if((pred_expert[j:j+2]==np.array([2,0])).all()):\n",
    "            pred_expert[j+1] = 2\n",
    "    for j in range(len(pred_expert)-2):\n",
    "        if(pred_expert[j+1] != pred_expert[j] and pred_expert[j+1] != pred_expert[j+2]):\n",
    "            pred_expert[j+1] = pred_expert[j]\n",
    "    df = pd.DataFrame(pred_expert)\n",
    "    df[df[0] == 0] = 'P'\n",
    "    df[df[0] == 1] = 'S'\n",
    "    df[df[0] == 2] = 'W'\n",
    "    print(df[0].value_counts(normalize=True))\n",
    "    dists.append(df[0].value_counts(normalize=True))\n",
    "    df.to_csv(f'data/aging/{i}_pred.csv',index=False)\n",
    "\n",
    "    offset = 10e7       #epoch time period\n",
    "    rename_dict = {'W':'Sleep-Wake', 'S':'Sleep-SWS', 'P':'Sleep-Paradoxical', 'X':''}\n",
    "\n",
    "    csv_filename = f'data/aging/{i}_pred.csv'\n",
    "    zdb_filename = f'data/aging/22-AGING-{i}.zdb'\n",
    "\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    try:\n",
    "        conn = sqlite3.connect(zdb_filename)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #drop this table - creates issues\n",
    "    query = \"DROP TABLE IF EXISTS temporary_scoring_marker;\"\n",
    "    cur.execute(query)\n",
    "\n",
    "    #get keyid of scoring\n",
    "    query = \"SELECT MAX(id) FROM scoring_revision WHERE name='Machine Data'\"\n",
    "    cur.execute(query)\n",
    "    keyid = cur.fetchall()[0][0]\n",
    "\n",
    "    #get starting point for scoring\n",
    "    query = \"SELECT id FROM scoring_marker WHERE type LIKE 'Sleep%' AND key_id='\"+str(keyid)+\"';\"\n",
    "    cur.execute(query)\n",
    "    startid = cur.fetchall()[0][0]\n",
    "\n",
    "    #get start time to crreate epochs\n",
    "    query = 'SELECT starts_at FROM scoring_marker WHERE id = '+str(startid)+\";\"\n",
    "    cur.execute(query)\n",
    "    start_time = cur.fetchall()[0][0]\n",
    "    stop_time = 0\n",
    "\n",
    "    #delete first score before adding machine data\n",
    "    query = \"DELETE FROM scoring_marker;\"\n",
    "    cur.execute(query)\n",
    "\n",
    "    #insert new epochs with scoring into the table\n",
    "    for i in range(len(df)):\n",
    "        #calculate epoch\n",
    "        if i != 0:\n",
    "            start_time = stop_time\n",
    "        stop_time = start_time+offset\n",
    "\n",
    "        score = rename_dict[df.at[i,'0']]\n",
    "        #insert epoch\n",
    "        query = f\"\"\"\n",
    "                INSERT INTO scoring_marker \n",
    "                (starts_at, ends_at, notes, type, location, is_deleted, key_id)\n",
    "                VALUES \n",
    "                ({start_time}, {stop_time}, '', '{score}', '', 0, {keyid});\n",
    "                \"\"\" \n",
    "        cur.execute(query)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame()\n",
    "for dist in dists:\n",
    "    tmp = pd.concat([tmp,dist],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(tmp.T['P'].reset_index(drop=True),fill=True)\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.title(\"Paradoxical Proportion Distribution Over Aging Cohort\")\n",
    "plt.savefig(\"p.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(tmp.T['S'].reset_index(drop=True),color='green',fill=True)\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.title(\"Slow Wave Proportion Distribution Over Aging Cohort\")\n",
    "plt.savefig(\"s.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(tmp.T['W'].reset_index(drop=True),color='red',fill=True)\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.title(\"Wakefulness Proportion Distribution Over Aging Cohort\")\n",
    "plt.savefig(\"w.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lib.utils import load_raw_by_path\n",
    "from torch import nn\n",
    "from torch.nn.functional import batch_norm,relu\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "EEG_1 = [1,8,14,15,16]\n",
    "EEG_2 = [3,4,5,6,7,9,10,11,12,13,17]\n",
    "i = 1\n",
    "y_plot = np.array([])\n",
    "raw = load_raw_by_path(f'aging/22-AGING-{i}.edf').get_data(picks=['EEG','EMG'])\n",
    "if(i in EEG_1):\n",
    "    eeg = raw[0]\n",
    "elif(i in EEG_2):\n",
    "    eeg = raw[1]\n",
    "else:\n",
    "    print(\"error\")\n",
    "del raw\n",
    "eeg = eeg.reshape(-1,5000)\n",
    "print(\"Centering\")\n",
    "eeg_centered = eeg - eeg.mean(axis=1).reshape(-1,1)\n",
    "del eeg\n",
    "std = eeg_centered.std(axis=1)\n",
    "std[np.where(std==0)[0]] = 1\n",
    "eeg_norm = eeg_centered/std.reshape(-1,1)\n",
    "del eeg_centered\n",
    "del std\n",
    "X = torch.from_numpy(eeg_norm.reshape(-1,1,5000)).float()\n",
    "del eeg_norm\n",
    "print(X.isinf().any())\n",
    "X = X[:,:,::10]\n",
    "pred_expert = pd.read_csv(f'aging/{i}_pred.csv')\n",
    "for pred in pred_expert.iloc:\n",
    "    y_plot = np.concatenate([y_plot,np.array([pred[0]]*50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([y_plot,X.flatten()[::10]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13378000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(X.flatte.iloc[:50*90])\n",
    "fig.show(renderer='browser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
