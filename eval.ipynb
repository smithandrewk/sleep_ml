{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'best_dev_f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'best_dev_f1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# info_df = df[['start_time','sequence_length','best_dev_loss','num_layers','bidirectional','training_stride','dropout','bidirectional','lr','wd','batch_size']]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# display(info_df)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# display(info_df.sort_values(by='best_dev_loss'))\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mplot_loss_curves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmoving_window_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlstm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sleep/sleep_ml/sage/utils.py:150\u001b[0m, in \u001b[0;36mplot_loss_curves\u001b[0;34m(plot_df, moving_window_length, lstm)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_loss_curves\u001b[39m(plot_df,moving_window_length,lstm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 150\u001b[0m     plot_df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mplot_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_dev_f1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_dev_f1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    151\u001b[0m     plot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_dev_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m plot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_dev_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    152\u001b[0m     plot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_dev_f1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m plot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_dev_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'best_dev_f1'"
     ]
    }
   ],
   "source": [
    "from lib.ekyn import *\n",
    "from lib.env import *\n",
    "from sage.utils import *\n",
    "from sage.models import *\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "states = {}\n",
    "\n",
    "for experiment in os.listdir(f'{EXPERIMENTS_PATH}'):\n",
    "    if experiment == '.Trash-1000':\n",
    "        continue\n",
    "    state = torch.load(f'{EXPERIMENTS_PATH}/{experiment}/state.pt',map_location='cpu',weights_only=False)\n",
    "    states[experiment] = state\n",
    "\n",
    "df = pd.DataFrame([states[experiment] for experiment in states])\n",
    "pd.set_option('display.max_rows', 500)\n",
    "df = df.sort_values(by='start_time',ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "# info_df = df[['start_time','sequence_length','best_dev_loss','num_layers','bidirectional','training_stride','dropout','bidirectional','lr','wd','batch_size']]\n",
    "# display(info_df)\n",
    "# display(info_df.sort_values(by='best_dev_loss'))\n",
    "plot_loss_curves(df,moving_window_length=1,lstm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>trainlossi</th>\n",
       "      <th>testlossi</th>\n",
       "      <th>best_dev_loss</th>\n",
       "      <th>model</th>\n",
       "      <th>scheduler</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>best_model_wts</th>\n",
       "      <th>...</th>\n",
       "      <th>robust</th>\n",
       "      <th>norm</th>\n",
       "      <th>dropout</th>\n",
       "      <th>stem_kernel_size</th>\n",
       "      <th>widthi</th>\n",
       "      <th>depthi</th>\n",
       "      <th>patience</th>\n",
       "      <th>epochs</th>\n",
       "      <th>device</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024_22_08_17_10_52</td>\n",
       "      <td>11.661983</td>\n",
       "      <td>[0.46395566765608404, 0.329041939897415, 0.297...</td>\n",
       "      <td>[0.3427402692682603, 0.35192406144650545, 0.27...</td>\n",
       "      <td>0.230772</td>\n",
       "      <td>ResNetv2(\\n  (stem): Conv1d(1, 4, kernel_size=...</td>\n",
       "      <td>&lt;torch.optim.lr_scheduler.ReduceLROnPlateau ob...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>AdamW (\\nParameter Group 0\\n    amsgrad: False...</td>\n",
       "      <td>{'stem.weight': [[tensor([ 0.5324, -0.3125,  0...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>batch</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 8, 16]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>cuda:0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_time  execution_time  \\\n",
       "0  2024_22_08_17_10_52       11.661983   \n",
       "\n",
       "                                          trainlossi  \\\n",
       "0  [0.46395566765608404, 0.329041939897415, 0.297...   \n",
       "\n",
       "                                           testlossi  best_dev_loss  \\\n",
       "0  [0.3427402692682603, 0.35192406144650545, 0.27...       0.230772   \n",
       "\n",
       "                                               model  \\\n",
       "0  ResNetv2(\\n  (stem): Conv1d(1, 4, kernel_size=...   \n",
       "\n",
       "                                           scheduler           criterion  \\\n",
       "0  <torch.optim.lr_scheduler.ReduceLROnPlateau ob...  CrossEntropyLoss()   \n",
       "\n",
       "                                           optimizer  \\\n",
       "0  AdamW (\\nParameter Group 0\\n    amsgrad: False...   \n",
       "\n",
       "                                      best_model_wts  ... robust   norm  \\\n",
       "0  {'stem.weight': [[tensor([ 0.5324, -0.3125,  0...  ...  False  batch   \n",
       "\n",
       "   dropout  stem_kernel_size      widthi     depthi  patience  epochs  device  \\\n",
       "0      0.1                 3  [4, 8, 16]  [2, 2, 2]       100     500  cuda:0   \n",
       "\n",
       "  fold  \n",
       "0    0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lib.ekyn import *\n",
    "\n",
    "MODEL_ID = f'2024_16_08_12_48_06'\n",
    "\n",
    "ekyn_ids = get_ekyn_ids()\n",
    "train_ids,test_ids = train_test_split(ekyn_ids,test_size=.2,shuffle=True,random_state=0)\n",
    "print(train_ids,test_ids)\n",
    "state = torch.load(f'{EXPERIMENTS_PATH}/{MODEL_ID}/state.pt',map_location='cpu',weights_only=False)\n",
    "model = copy.deepcopy(state['model'])\n",
    "model.load_state_dict(state['best_model_wts'])\n",
    "trainloader,testloader = get_sequenced_dataloaders(batch_size=state['batch_size'],sequence_length=state['sequence_length'])\n",
    "# trainloader,testloader = get_epoched_dataloaders(batch_size=state['batch_size'],robust=False)\n",
    "loss,y_true,y_pred = evaluate(dataloader=testloader,model=model,criterion=state['criterion'],device='cuda')\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,normalize='true',colorbar=False)\n",
    "plt.title(f'f1 : {f1_score(y_true,y_pred,average=\"macro\"):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming df is populated with necessary data\n",
    "df = {}\n",
    "\n",
    "# Initialize the figure and axes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
    "\n",
    "# Loop through test IDs\n",
    "for id in test_ids:\n",
    "    # Load data and perform necessary calculations\n",
    "    X, y = load_ekyn_pt(id=id, condition='PF')\n",
    "\n",
    "    # ECDF plot\n",
    "    std, mean = torch.std_mean(X[torch.where(y.argmax(axis=1) == 1)[0]], dim=1)\n",
    "    sns.ecdfplot(std, linewidth=2, label=id, ax=axes[0])\n",
    "\n",
    "    # Calculate F1 score\n",
    "    dataloader = get_epoched_dataloader_for_ids(ids=[id],robust=state['robust'])\n",
    "    loss, y_true, y_pred = evaluate(dataloader=dataloader, model=model, criterion=state['criterion'], device='cuda')\n",
    "    f1 = float(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "    # Bar plot\n",
    "    sns.barplot(x=[id], y=[f1], ax=axes[1])  # Plotting F1 score for each ID\n",
    "\n",
    "\n",
    "# for id in train_ids:\n",
    "#     # Load data and perform necessary calculations\n",
    "#     X, y = load_ekyn_pt(id=id, condition='PF')\n",
    "\n",
    "#     # ECDF plot\n",
    "#     std, mean = torch.std_mean(X[torch.where(y.argmax(axis=1) == 1)[0]], dim=1)\n",
    "#     sns.ecdfplot(std, linewidth=.5, label=id, ax=axes[0],color='black')\n",
    "\n",
    "# Final adjustments\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim([0, .000150])\n",
    "axes[1].set_ylim([0, 1])  # Adjust y-axis limits for the bar plot\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
