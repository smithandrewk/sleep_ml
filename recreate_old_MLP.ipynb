{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import *\n",
    "from lib.datasets import Dataset2p0\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from lib.env import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lib.utils import UniformRandomClassifier,ProportionalRandomClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (train_ids,test_id) in tqdm(get_leave_one_out_cv_ids_for_ekyn()):\n",
    "    X_train,y_train = get_trainloader_windowed(train_ids)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    X_test,y_test = get_testloader_windowed(test_id)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm_grid(y_test.argmax(axis=1),y_pred.argmax(axis=1))\n",
    "    eval.append(metrics(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[fold['precision'] for fold in np.load('proportional_random_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['recall'] for fold in np.load('proportional_random_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['f1'] for fold in np.load('proportional_random_eval_unscaled.npy',allow_pickle=True)],['proportional']*16],index=['precision','recall','f1','classifier']).T\n",
    "df = pd.concat([df,pd.DataFrame([[fold['precision'] for fold in np.load('uniform_random_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['recall'] for fold in np.load('uniform_random_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['f1'] for fold in np.load('uniform_random_eval_unscaled.npy',allow_pickle=True)],['uniform']*16],index=['precision','recall','f1','classifier']).T])\n",
    "df = pd.concat([df,pd.DataFrame([[fold['precision'] for fold in np.load('mlp_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['recall'] for fold in np.load('mlp_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['f1'] for fold in np.load('mlp_eval_unscaled.npy',allow_pickle=True)],['mlp']*16],index=['precision','recall','f1','classifier']).T])\n",
    "df = pd.concat([df,pd.DataFrame([[fold['precision'] for fold in np.load('rf_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['recall'] for fold in np.load('rf_eval_unscaled.npy',allow_pickle=True)],\n",
    "    [fold['f1'] for fold in np.load('rf_eval_unscaled.npy',allow_pickle=True)],['rf']*16],index=['precision','recall','f1','classifier']).T])\n",
    "df[['precision','recall','f1']] = df[['precision','recall','f1']].astype(float)\n",
    "df['classifier'] = df['classifier'].astype(str)\n",
    "df = df.reset_index(drop=True)\n",
    "sns.violinplot(data=df,x='f1',y='classifier',split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids,test_id = get_leave_one_out_cv_ids_for_ekyn()[0]\n",
    "X_train,y_train = get_trainloader_windowed(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_dev,y_train,y_dev = train_test_split(X_train,y_train,test_size=.1,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMLP(nn.Module):\n",
    "    def __init__(self,input_size=210) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size,512)\n",
    "        self.d1 = nn.Dropout1d(p=.1)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.d2 = nn.Dropout1d(p=.2)\n",
    "\n",
    "        self.fc3 = nn.Linear(512,3)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = relu(x)\n",
    "        x = self.d1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = relu(x)\n",
    "        x = self.d2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models import MLP\n",
    "model = MLP(input_size=210).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "trainloader = DataLoader(TensorDataset(X_train,y_train),batch_size=32,shuffle=True)\n",
    "devloader = DataLoader(TensorDataset(X_dev,y_dev),batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "loss_tr = []\n",
    "\n",
    "model.train()\n",
    "loss_dev = []\n",
    "\n",
    "for i in range(100):\n",
    "    loss_tr_total = 0\n",
    "\n",
    "    for (X_tr,y_tr) in tqdm(trainloader):\n",
    "        X_tr,y_tr = X_tr.to(DEVICE),y_tr.to(DEVICE)\n",
    "        logits = model(X_tr)\n",
    "        loss = criterion(logits,y_tr)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossi.append(loss.item())\n",
    "        loss_tr_total += loss.item()\n",
    "    loss_tr.append(loss_tr_total/len(trainloader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_dev_total = 0\n",
    "        for (X_dv,y_dv) in devloader:\n",
    "            X_dv,y_dv = X_dv.to(DEVICE),y_dv.to(DEVICE)\n",
    "            logits = model(X_dv)\n",
    "            loss = criterion(logits,y_dv)\n",
    "            loss_dev_total += loss.item()\n",
    "        loss_dev.append(loss_dev_total/len(devloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_tr)\n",
    "plt.plot(loss_dev)\n",
    "# .62 with MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,metrics,y_true,y_pred,y_logits = evaluate(trainloader,model,criterion)\n",
    "cm_grid(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = get_testloader_windowed(test_id)\n",
    "testloader = DataLoader(TensorDataset(X_test,y_test),batch_size=32,shuffle=True)\n",
    "\n",
    "loss,metrics,y_true,y_pred,y_logits = evaluate(trainloader,model,criterion)\n",
    "cm_grid(y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
